<!DOCTYPE html>
<html lang="en">
    <!-- title -->




<!-- keywords -->




<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" >
    <meta name="author" content="keefe">
    <meta name="renderer" content="webkit">
    <meta name="copyright" content="keefe">
    
    <meta name="keywords" content="蒙特卡洛家的树,蒙特卡洛家的树,念去去的博客,keefe">
    
    <meta name="description" content="">
    <meta http-equiv="Cache-control" content="no-cache">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <title>caffe源码阅读《六》base_conv_layer · 蒙特卡洛家的树</title>
    <style type="text/css">
    @font-face {
        font-family: 'Oswald-Regular';
        src: url("/font/Oswald-Regular.ttf");
    }

    body {
        margin: 0;
    }

    header,
    footer,
    .back-top,
    .sidebar,
    .container,
    .site-intro-meta,
    .toc-wrapper {
        display: none;
    }

    .site-intro {
        position: relative;
        z-index: 3;
        width: 100%;
        /* height: 50vh; */
        overflow: hidden;
    }

    .site-intro-placeholder {
        position: absolute;
        z-index: -2;
        top: 0;
        left: 0;
        width: calc(100% + 300px);
        height: 100%;
        background: repeating-linear-gradient(-45deg, #444 0, #444 80px, #333 80px, #333 160px);
        background-position: center center;
        transform: translate3d(-226px, 0, 0);
        animation: gradient-move 2.5s ease-out 0s infinite;
    }

    @keyframes gradient-move {
        0% {
            transform: translate3d(-226px, 0, 0);
        }
        100% {
            transform: translate3d(0, 0, 0);
        }
    }

</style>

    <link rel="preload" href= "/css/style.css?v=20180824" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    <link rel="stylesheet" href= "/css/mobile.css?v=20180824" media="(max-width: 980px)">
    
    <link rel="preload" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'" />
    
    <!-- /*! loadCSS. [c]2017 Filament Group, Inc. MIT License */
/* This file is meant as a standalone workflow for
- testing support for link[rel=preload]
- enabling async CSS loading in browsers that do not support rel=preload
- applying rel preload css once loaded, whether supported or not.
*/ -->
<script>
(function( w ){
	"use strict";
	// rel=preload support test
	if( !w.loadCSS ){
		w.loadCSS = function(){};
	}
	// define on the loadCSS obj
	var rp = loadCSS.relpreload = {};
	// rel=preload feature support test
	// runs once and returns a function for compat purposes
	rp.support = (function(){
		var ret;
		try {
			ret = w.document.createElement( "link" ).relList.supports( "preload" );
		} catch (e) {
			ret = false;
		}
		return function(){
			return ret;
		};
	})();

	// if preload isn't supported, get an asynchronous load by using a non-matching media attribute
	// then change that media back to its intended value on load
	rp.bindMediaToggle = function( link ){
		// remember existing media attr for ultimate state, or default to 'all'
		var finalMedia = link.media || "all";

		function enableStylesheet(){
			link.media = finalMedia;
		}

		// bind load handlers to enable media
		if( link.addEventListener ){
			link.addEventListener( "load", enableStylesheet );
		} else if( link.attachEvent ){
			link.attachEvent( "onload", enableStylesheet );
		}

		// Set rel and non-applicable media type to start an async request
		// note: timeout allows this to happen async to let rendering continue in IE
		setTimeout(function(){
			link.rel = "stylesheet";
			link.media = "only x";
		});
		// also enable media after 3 seconds,
		// which will catch very old browsers (android 2.x, old firefox) that don't support onload on link
		setTimeout( enableStylesheet, 3000 );
	};

	// loop through link elements in DOM
	rp.poly = function(){
		// double check this to prevent external calls from running
		if( rp.support() ){
			return;
		}
		var links = w.document.getElementsByTagName( "link" );
		for( var i = 0; i < links.length; i++ ){
			var link = links[ i ];
			// qualify links to those with rel=preload and as=style attrs
			if( link.rel === "preload" && link.getAttribute( "as" ) === "style" && !link.getAttribute( "data-loadcss" ) ){
				// prevent rerunning on link
				link.setAttribute( "data-loadcss", true );
				// bind listeners to toggle media back
				rp.bindMediaToggle( link );
			}
		}
	};

	// if unsupported, run the polyfill
	if( !rp.support() ){
		// run once at least
		rp.poly();

		// rerun poly on an interval until onload
		var run = w.setInterval( rp.poly, 500 );
		if( w.addEventListener ){
			w.addEventListener( "load", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		} else if( w.attachEvent ){
			w.attachEvent( "onload", function(){
				rp.poly();
				w.clearInterval( run );
			} );
		}
	}


	// commonjs
	if( typeof exports !== "undefined" ){
		exports.loadCSS = loadCSS;
	}
	else {
		w.loadCSS = loadCSS;
	}
}( typeof global !== "undefined" ? global : this ) );
</script>

    <link rel="icon" href= "/avatar/tree.jpg" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js" as="script" />
    <link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js" as="script" />
    <link rel="preload" href="/scripts/main.js" as="script" />
    <link rel="preload" as="font" href="/font/Oswald-Regular.ttf" crossorigin>
    <link rel="preload" as="font" href="https://at.alicdn.com/t/font_327081_1dta1rlogw17zaor.woff" crossorigin>
    
    <!-- fancybox -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" defer></script>
    <!-- 百度统计  -->
    
    <!-- 谷歌统计  -->
    
<meta name="generator" content="Hexo 4.2.0"></head>

    
        <body class="post-body">
    
    
<header class="header">

    <div class="read-progress"></div>
    <div class="header-sidebar-menu">&#xe775;</div>
    <!-- post页的toggle banner  -->
    
    <div class="banner">
            <div class="blog-title">
                <a href="/" >蒙特卡洛家的树</a>
            </div>
            <div class="post-title">
                <a href="#" class="post-name">caffe源码阅读《六》base_conv_layer</a>
            </div>
    </div>
    
    <a class="home-link" href=/>蒙特卡洛家的树</a>
</header>
    <div class="wrapper">
        <div class="site-intro" style="







height:50vh;
">
    
    <!-- 主页  -->
    
    
    <!-- 404页  -->
            
    <div class="site-intro-placeholder"></div>
    <div class="site-intro-img" style="background-image: url(/intro/post-bg.jpg)"></div>
    <div class="site-intro-meta">
        <!-- 标题  -->
        <h1 class="intro-title">
            <!-- 主页  -->
            
            caffe源码阅读《六》base_conv_layer
            <!-- 404 -->
            
        </h1>
        <!-- 副标题 -->
        <p class="intro-subtitle">
            <!-- 主页副标题  -->
            
            
            <!-- 404 -->
            
        </p>
        <!-- 文章页meta -->
        
            <div class="post-intros">
                <!-- 文章页标签  -->
                
                    <div class= post-intro-tags >
    
        <a class="post-tag" href="javascript:void(0);" data-tags = "caffe">caffe</a>
    
</div>
                
                
                    <div class="post-intro-read">
                        <span>Word count: <span class="post-count word-count">4.8k</span>Reading time: <span class="post-count reading-time">22 min</span></span>
                    </div>
                
                <div class="post-intro-meta">
                    <span class="post-intro-calander iconfont-archer">&#xe676;</span>
                    <span class="post-intro-time">2020/03/05</span>
                    
                    <span id="busuanzi_container_page_pv" class="busuanzi-pv">
                        <span class="iconfont-archer">&#xe602;</span>
                        <span id="busuanzi_value_page_pv"></span>
                    </span>
                    
                    <span class="shareWrapper">
                        <span class="iconfont-archer shareIcon">&#xe71d;</span>
                        <span class="shareText">Share</span>
                        <ul class="shareList">
                            <li class="iconfont-archer share-qr" data-type="qr">&#xe75b;
                                <div class="share-qrcode"></div>
                            </li>
                            <li class="iconfont-archer" data-type="weibo">&#xe619;</li>
                            <li class="iconfont-archer" data-type="qzone">&#xe62e;</li>
                            <li class="iconfont-archer" data-type="twitter">&#xe634;</li>
                            <li class="iconfont-archer" data-type="facebook">&#xe67a;</li>
                        </ul>
                    </span>
                </div>
            </div>
        
    </div>
</div>
        <script>
 
  // get user agent
  var browser = {
    versions: function () {
      var u = window.navigator.userAgent;
      return {
        userAgent: u,
        trident: u.indexOf('Trident') > -1, //IE内核
        presto: u.indexOf('Presto') > -1, //opera内核
        webKit: u.indexOf('AppleWebKit') > -1, //苹果、谷歌内核
        gecko: u.indexOf('Gecko') > -1 && u.indexOf('KHTML') == -1, //火狐内核
        mobile: !!u.match(/AppleWebKit.*Mobile.*/), //是否为移动终端
        ios: !!u.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/), //ios终端
        android: u.indexOf('Android') > -1 || u.indexOf('Linux') > -1, //android终端或者uc浏览器
        iPhone: u.indexOf('iPhone') > -1 || u.indexOf('Mac') > -1, //是否为iPhone或者安卓QQ浏览器
        iPad: u.indexOf('iPad') > -1, //是否为iPad
        webApp: u.indexOf('Safari') == -1, //是否为web应用程序，没有头部与底部
        weixin: u.indexOf('MicroMessenger') == -1, //是否为微信浏览器
        uc: u.indexOf('UCBrowser') > -1 //是否为android下的UC浏览器
      };
    }()
  }
  console.log("userAgent:" + browser.versions.userAgent);

  // callback
  function fontLoaded() {
    console.log('font loaded');
    if (document.getElementsByClassName('site-intro-meta')) {
      document.getElementsByClassName('intro-title')[0].classList.add('intro-fade-in');
      document.getElementsByClassName('intro-subtitle')[0].classList.add('intro-fade-in');
      var postIntros = document.getElementsByClassName('post-intros')[0]
      if (postIntros) {
        postIntros.classList.add('post-fade-in');
      }
    }
  }

  // UC不支持跨域，所以直接显示
  function asyncCb(){
    if (browser.versions.uc) {
      console.log("UCBrowser");
      fontLoaded();
    } else {
      WebFont.load({
        custom: {
          families: ['Oswald-Regular']
        },
        loading: function () {  //所有字体开始加载
          // console.log('loading');
        },
        active: function () {  //所有字体已渲染
          fontLoaded();
        },
        inactive: function () { //字体预加载失败，无效字体或浏览器不支持加载
          console.log('inactive: timeout');
          fontLoaded();
        },
        timeout: 5000 // Set the timeout to two seconds
      });
    }
  }

  function asyncErr(){
    console.warn('script load from CDN failed, will load local script')
  }

  // load webfont-loader async, and add callback function
  function async(u, cb, err) {
    var d = document, t = 'script',
      o = d.createElement(t),
      s = d.getElementsByTagName(t)[0];
    o.src = u;
    if (cb) { o.addEventListener('load', function (e) { cb(null, e); }, false); }
    if (err) { o.addEventListener('error', function (e) { err(null, e); }, false); }
    s.parentNode.insertBefore(o, s);
  }

  var asyncLoadWithFallBack = function(arr, success, reject) {
      var currReject = function(){
        reject()
        arr.shift()
        if(arr.length)
          async(arr[0], success, currReject)
        }

      async(arr[0], success, currReject)
  }

  asyncLoadWithFallBack([
    "https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.min.js", 
    "https://cdn.bootcss.com/webfont/1.6.28/webfontloader.js",
    "/lib/webfontloader.min.js"
  ], asyncCb, asyncErr)
</script>        
        <img class="loading" src="/assets/loading.svg" style="display: block; margin: 6rem auto 0 auto; width: 6rem; height: 6rem;" />
        <div class="container container-unloaded">
            <main class="main post-page">
    <article class="article-entry">
        <p><code>BaseConvolutionLayer</code>是所有卷积层的基类。为什么卷积层还需要基类呢？因为再caffe里除了 <code>ConvolutionLayer</code>还有 <code>DeconvolutionLayer</code></p>
<h1 id="BaseConvolutionLayer-类"><a href="#BaseConvolutionLayer-类" class="headerlink" title="BaseConvolutionLayer 类"></a>BaseConvolutionLayer 类</h1><h2 id="BaseConvolutionLayer-构造函数"><a href="#BaseConvolutionLayer-构造函数" class="headerlink" title="BaseConvolutionLayer 构造函数"></a>BaseConvolutionLayer 构造函数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">explicit BaseConvolutionLayer(const LayerParameter&amp; param)</span><br><span class="line">    : Layer&lt;Dtype&gt;(param) &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>因为它是一个基类，所以这个构造函数就写成了空的，传入了 <code>param</code>这一个参数，但是什么都没做，传一个参数把方向确定了，具体内容留给子类去实现。</p>
<h2 id="LayerSetUp-函数"><a href="#LayerSetUp-函数" class="headerlink" title="LayerSetUp 函数"></a>LayerSetUp 函数</h2><p>这个 <code>LayerSetUp</code>函数是很关键的，因为它实现了，而且实现的非常长。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">virtual void LayerSetUp(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">    const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</span><br></pre></td></tr></table></figure>
<p>第一步首先加载我们这一个卷积的参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ConvolutionParameter conv_param &#x3D; this-&gt;layer_param_.convolution_param();</span><br></pre></td></tr></table></figure>
<p>这个参数是从 <code>layer_param_</code>这个变量里来的，而这个变量里的参数又是从哪里来的呢？这就要从 <code>Layer</code>这个类说起了，因为我们这个<code>BaseConvolutionLayer</code>是继承的<code>Layer</code>这个类。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename Dtype&gt;</span><br><span class="line">class BaseConvolutionLayer : public Layer&lt;Dtype&gt;</span><br></pre></td></tr></table></figure>
<p>所以一切的变量也是定义在<code>Layer</code>这个类里面的，我们去<code>Layer</code>这个类里面找一下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;** The protobuf that stores the layer parameters *&#x2F;</span><br><span class="line">LayerParameter layer_param_;</span><br></pre></td></tr></table></figure>
<p>它定义的这个 <code>LayerParameter</code>是在 <code>proto</code>文件里</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class LayerParameter : public ::google::protobuf::Message &#x2F;* @@protoc_insertion_point(class_definition:caffe.LayerParameter) *&#x2F;</span><br></pre></td></tr></table></figure>
<p>而 <code>convolution_param</code>函数把参数变量的指针返回回来，实际上就是把参数返回到了这个类里面。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">inline const ::caffe::ConvolutionParameter&amp; LayerParameter::convolution_param() const &#123;</span><br><span class="line">  &#x2F;&#x2F; @@protoc_insertion_point(field_get:caffe.LayerParameter.convolution_param)</span><br><span class="line">  return convolution_param_ !&#x3D; NULL ? *convolution_param_ : *default_instance_-&gt;convolution_param_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接着问一下是不是要强制把矩阵转成caffe的矩阵形式，就是我们说的 <code>im2col</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">force_nd_im2col_ &#x3D; conv_param.force_nd_im2col();</span><br></pre></td></tr></table></figure>
<p>这个 <code>im2col</code>真的非常重要，我觉得这个是caffe计算部分的核心，建议大家一定要认真的学习这一块。<br>接着获取bottom的 <code>channel_axis</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">channel_axis_ &#x3D; bottom[0]-&gt;CanonicalAxisIndex(conv_param.axis());</span><br></pre></td></tr></table></figure>
<p>这一步不是获取 <code>channel</code>的数量，而是返回 <code>channel</code>在 <code>shape</code>里是第几位，比方说 <code>shape</code>是 <code>3<em>224</em>224</code>,那么 <code>channel</code>就在第0位，这一步返回值就是0.<br>所以真正空间形状的开始就是从第1位开始的，接下来这个函数就是返回的空间形状开始的那个axis</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">const int first_spatial_axis &#x3D; channel_axis_ + 1;</span><br></pre></td></tr></table></figure>
<p>然后是总共的axis的数量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">const int num_axes &#x3D; bottom[0]-&gt;num_axes();</span><br></pre></td></tr></table></figure>
<p>接下来是 <code>num_spatial_axes_</code>,这个代表的就是真正空间的axis的数量，也就是排除了channel那一层的数量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_spatial_axes_ &#x3D; num_axes - first_spatial_axis;</span><br></pre></td></tr></table></figure>
<p>检查一下 <code>num_spatial_axes_</code>是不是大于0的</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CHECK_GE(num_spatial_axes_, 0);</span><br></pre></td></tr></table></figure>
<p>因为如果不是大于0的就说明空间的维度不存在，这显然是不可能的，就会直接抛出异常。<br>然后声明了一个变量，专门去存空间的形状。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;int&gt; spatial_dim_blob_shape(1, std::max(num_spatial_axes_, 1));</span><br></pre></td></tr></table></figure>
<p>所以刚才才要了空间形状的起始位置，因为在这里等着，准备拷贝空间形状。<br>因为卷积核的空间维度数量要和图片是一样的，所以要把卷积核 <code>Reshape</code>了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Setup filter kernel dimensions (kernel_shape_).</span><br><span class="line">kernel_shape_.Reshape(spatial_dim_blob_shape);</span><br></pre></td></tr></table></figure>
<p>注意啊，这里是维度是一样的，并不是形状是一样的，也就是说假设图片是个2维图片，那么卷积核也就必须是2维的。假设图片大小是224<em>224，那么卷积核是3</em>3就可以和它匹配。假设图片是三维的，比方说224<em>224</em>224，那么卷积核也就必须是三维的，比方说5<em>5</em>5.<br>接着准备对 <code>kernel_shape_</code>赋值了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int* kernel_shape_data &#x3D; kernel_shape_.mutable_cpu_data();</span><br></pre></td></tr></table></figure>
<p>我们知道 <code>mutable_cpu_data</code>存的是最新修改的数据的指针，所以这里取了这个地址，就准备开始赋值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">if (conv_param.has_kernel_h() || conv_param.has_kernel_w()) &#123;</span><br><span class="line">  CHECK_EQ(num_spatial_axes_, 2)</span><br><span class="line">      &lt;&lt; &quot;kernel_h &amp; kernel_w can only be used for 2D convolution.&quot;;</span><br><span class="line">  CHECK_EQ(0, conv_param.kernel_size_size())</span><br><span class="line">      &lt;&lt; &quot;Either kernel_size or kernel_h&#x2F;w should be specified; not both.&quot;;</span><br><span class="line">  kernel_shape_data[0] &#x3D; conv_param.kernel_h();</span><br><span class="line">  kernel_shape_data[1] &#x3D; conv_param.kernel_w();</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  const int num_kernel_dims &#x3D; conv_param.kernel_size_size();</span><br><span class="line">  CHECK(num_kernel_dims &#x3D;&#x3D; 1 || num_kernel_dims &#x3D;&#x3D; num_spatial_axes_)</span><br><span class="line">      &lt;&lt; &quot;kernel_size must be specified once, or once per spatial dimension &quot;</span><br><span class="line">      &lt;&lt; &quot;(kernel_size specified &quot; &lt;&lt; num_kernel_dims &lt;&lt; &quot; times; &quot;</span><br><span class="line">      &lt;&lt; num_spatial_axes_ &lt;&lt; &quot; spatial dims).&quot;;</span><br><span class="line">    for (int i &#x3D; 0; i &lt; num_spatial_axes_; ++i) &#123;</span><br><span class="line">      kernel_shape_data[i] &#x3D;</span><br><span class="line">          conv_param.kernel_size((num_kernel_dims &#x3D;&#x3D; 1) ? 0 : i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里判断了，如果是二维的话，那么就从参数里面读取高和宽，如果是多维的话，就一维一维的从参数里面去读取。<br>最后检查一下空间的维度有没有存在0</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (int i &#x3D; 0; i &lt; num_spatial_axes_; ++i) &#123;</span><br><span class="line">  CHECK_GT(kernel_shape_data[i], 0) &lt;&lt; &quot;Filter dimensions must be nonzero.&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这一步很好理解，你总不能有高或者宽是0的图吧<br>接下来把 <code>stride_</code>这个blob也给它 <code>Reshape</code>一下，因为这个 <code>stride_</code> blob它是记录步长的一个blob，所以它的维度也得和我们这个图片是一致的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Setup stride dimensions (stride_).</span><br><span class="line">stride_.Reshape(spatial_dim_blob_shape);</span><br><span class="line">int* stride_data &#x3D; stride_.mutable_cpu_data();</span><br><span class="line">if (conv_param.has_stride_h() || conv_param.has_stride_w()) &#123;</span><br><span class="line">  CHECK_EQ(num_spatial_axes_, 2)</span><br><span class="line">      &lt;&lt; &quot;stride_h &amp; stride_w can only be used for 2D convolution.&quot;;</span><br><span class="line">  CHECK_EQ(0, conv_param.stride_size())</span><br><span class="line">      &lt;&lt; &quot;Either stride or stride_h&#x2F;w should be specified; not both.&quot;;</span><br><span class="line">  stride_data[0] &#x3D; conv_param.stride_h();</span><br><span class="line">  stride_data[1] &#x3D; conv_param.stride_w();</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  const int num_stride_dims &#x3D; conv_param.stride_size();</span><br><span class="line">  CHECK(num_stride_dims &#x3D;&#x3D; 0 || num_stride_dims &#x3D;&#x3D; 1 ||</span><br><span class="line">        num_stride_dims &#x3D;&#x3D; num_spatial_axes_)</span><br><span class="line">      &lt;&lt; &quot;stride must be specified once, or once per spatial dimension &quot;</span><br><span class="line">      &lt;&lt; &quot;(stride specified &quot; &lt;&lt; num_stride_dims &lt;&lt; &quot; times; &quot;</span><br><span class="line">      &lt;&lt; num_spatial_axes_ &lt;&lt; &quot; spatial dims).&quot;;</span><br><span class="line">  const int kDefaultStride &#x3D; 1;</span><br><span class="line">  for (int i &#x3D; 0; i &lt; num_spatial_axes_; ++i) &#123;</span><br><span class="line">    stride_data[i] &#x3D; (num_stride_dims &#x3D;&#x3D; 0) ? kDefaultStride :</span><br><span class="line">        conv_param.stride((num_stride_dims &#x3D;&#x3D; 1) ? 0 : i);</span><br><span class="line">    CHECK_GT(stride_data[i], 0) &lt;&lt; &quot;Stride dimensions must be nonzero.&quot;;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>和上面的卷积核是一样的。<br>然后是 <code>pad_</code>,和 <code>stride_</code>一模一样，也是给他形状赋一个值。padding就是卷积边界处理的长度。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Setup pad dimensions (pad_).</span><br><span class="line">pad_.Reshape(spatial_dim_blob_shape);</span><br><span class="line">int* pad_data &#x3D; pad_.mutable_cpu_data();</span><br><span class="line">if (conv_param.has_pad_h() || conv_param.has_pad_w()) &#123;</span><br><span class="line">  CHECK_EQ(num_spatial_axes_, 2)</span><br><span class="line">      &lt;&lt; &quot;pad_h &amp; pad_w can only be used for 2D convolution.&quot;;</span><br><span class="line">  CHECK_EQ(0, conv_param.pad_size())</span><br><span class="line">      &lt;&lt; &quot;Either pad or pad_h&#x2F;w should be specified; not both.&quot;;</span><br><span class="line">  pad_data[0] &#x3D; conv_param.pad_h();</span><br><span class="line">  pad_data[1] &#x3D; conv_param.pad_w();</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  const int num_pad_dims &#x3D; conv_param.pad_size();</span><br><span class="line">  CHECK(num_pad_dims &#x3D;&#x3D; 0 || num_pad_dims &#x3D;&#x3D; 1 ||</span><br><span class="line">        num_pad_dims &#x3D;&#x3D; num_spatial_axes_)</span><br><span class="line">      &lt;&lt; &quot;pad must be specified once, or once per spatial dimension &quot;</span><br><span class="line">      &lt;&lt; &quot;(pad specified &quot; &lt;&lt; num_pad_dims &lt;&lt; &quot; times; &quot;</span><br><span class="line">      &lt;&lt; num_spatial_axes_ &lt;&lt; &quot; spatial dims).&quot;;</span><br><span class="line">  const int kDefaultPad &#x3D; 0;</span><br><span class="line">  for (int i &#x3D; 0; i &lt; num_spatial_axes_; ++i) &#123;</span><br><span class="line">    pad_data[i] &#x3D; (num_pad_dims &#x3D;&#x3D; 0) ? kDefaultPad :</span><br><span class="line">        conv_param.pad((num_pad_dims &#x3D;&#x3D; 1) ? 0 : i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>还有决定这个图将被放大多少倍的 <code>dilation_</code>也是一样的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Setup dilation dimensions (dilation_).</span><br><span class="line">dilation_.Reshape(spatial_dim_blob_shape);</span><br><span class="line">int* dilation_data &#x3D; dilation_.mutable_cpu_data();</span><br><span class="line">const int num_dilation_dims &#x3D; conv_param.dilation_size();</span><br><span class="line">CHECK(num_dilation_dims &#x3D;&#x3D; 0 || num_dilation_dims &#x3D;&#x3D; 1 ||</span><br><span class="line">      num_dilation_dims &#x3D;&#x3D; num_spatial_axes_)</span><br><span class="line">    &lt;&lt; &quot;dilation must be specified once, or once per spatial dimension &quot;</span><br><span class="line">    &lt;&lt; &quot;(dilation specified &quot; &lt;&lt; num_dilation_dims &lt;&lt; &quot; times; &quot;</span><br><span class="line">    &lt;&lt; num_spatial_axes_ &lt;&lt; &quot; spatial dims).&quot;;</span><br><span class="line">const int kDefaultDilation &#x3D; 1;</span><br><span class="line">for (int i &#x3D; 0; i &lt; num_spatial_axes_; ++i) &#123;</span><br><span class="line">  dilation_data[i] &#x3D; (num_dilation_dims &#x3D;&#x3D; 0) ? kDefaultDilation :</span><br><span class="line">                     conv_param.dilation((num_dilation_dims &#x3D;&#x3D; 1) ? 0 : i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接着就要开始转成计算矩阵了。<br>首先判断一下图是不是1<em>1的，因为如果是1</em>1的话，那么这个计算就会省很多事情。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Special case: im2col is the identity for 1x1 convolution with stride 1</span><br><span class="line">&#x2F;&#x2F; and no padding, so flag for skipping the buffer and transformation.</span><br><span class="line">is_1x1_ &#x3D; true;</span><br><span class="line">for (int i &#x3D; 0; i &lt; num_spatial_axes_; ++i) &#123;</span><br><span class="line">  is_1x1_ &amp;&#x3D;</span><br><span class="line">      kernel_shape_data[i] &#x3D;&#x3D; 1 &amp;&amp; stride_data[i] &#x3D;&#x3D; 1 &amp;&amp; pad_data[i] &#x3D;&#x3D; 0;</span><br><span class="line">  if (!is_1x1_) &#123; break; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接着获取 <code>bottom</code>层的通道数，也就是输入的通道数，还有 <code>output</code>的数量，也就是输出的通道数,还有 <code>group</code>的数量，分 <code>group</code>的目的是为了指定哪些通道只能哪些卷积核做卷积，不相干的就不会卷积。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Configure output channels and groups.</span><br><span class="line">channels_ &#x3D; bottom[0]-&gt;shape(channel_axis_);</span><br><span class="line">num_output_ &#x3D; this-&gt;layer_param_.convolution_param().num_output();</span><br><span class="line">CHECK_GT(num_output_, 0);</span><br><span class="line">group_ &#x3D; this-&gt;layer_param_.convolution_param().group();</span><br><span class="line">CHECK_EQ(channels_ % group_, 0);</span><br><span class="line">CHECK_EQ(num_output_ % group_, 0)</span><br><span class="line">    &lt;&lt; &quot;Number of output should be multiples of group.&quot;;</span><br></pre></td></tr></table></figure>
<p>因为分组是均分的，所以判断了一下 <code>group</code>的数量是不是能被 <code>channel</code>的数量整除。<br>之后判断一下输入和输出顺序是不是设定了需要反过来。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">if (reverse_dimensions()) &#123;</span><br><span class="line">  conv_out_channels_ &#x3D; channels_;</span><br><span class="line">  conv_in_channels_ &#x3D; num_output_;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  conv_out_channels_ &#x3D; num_output_;</span><br><span class="line">  conv_in_channels_ &#x3D; channels_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果是反卷积这种的话就要把输入和输出的channel给反过来了。<br>定义一下权值的形状</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Handle the parameters: weights and biases.</span><br><span class="line">&#x2F;&#x2F; - blobs_[0] holds the filter weights</span><br><span class="line">&#x2F;&#x2F; - blobs_[1] holds the biases (optional)</span><br><span class="line">vector&lt;int&gt; weight_shape(2);</span><br><span class="line">weight_shape[0] &#x3D; conv_out_channels_;</span><br><span class="line">weight_shape[1] &#x3D; conv_in_channels_ &#x2F; group_;</span><br><span class="line">for (int i &#x3D; 0; i &lt; num_spatial_axes_; ++i) &#123;</span><br><span class="line">  weight_shape.push_back(kernel_shape_data[i]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后是 <code>bias</code>,因为这个 <code>bias</code>是可以选择开关的，所以首先判断了一下，如果开的话就定义一下这个偏置的形状.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bias_term_ &#x3D; this-&gt;layer_param_.convolution_param().bias_term();</span><br><span class="line">vector&lt;int&gt; bias_shape(bias_term_, num_output_);</span><br></pre></td></tr></table></figure>
<p>最后检查 <code>blob</code>的 <code>size</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">if (this-&gt;blobs_.size() &gt; 0) &#123;</span><br><span class="line">  CHECK_EQ(1 + bias_term_, this-&gt;blobs_.size())</span><br><span class="line">      &lt;&lt; &quot;Incorrect number of weight blobs.&quot;;</span><br><span class="line">  if (weight_shape !&#x3D; this-&gt;blobs_[0]-&gt;shape()) &#123;</span><br><span class="line">    Blob&lt;Dtype&gt; weight_shaped_blob(weight_shape);</span><br><span class="line">    LOG(FATAL) &lt;&lt; &quot;Incorrect weight shape: expected shape &quot;</span><br><span class="line">        &lt;&lt; weight_shaped_blob.shape_string() &lt;&lt; &quot;; instead, shape was &quot;</span><br><span class="line">        &lt;&lt; this-&gt;blobs_[0]-&gt;shape_string();</span><br><span class="line">  &#125;</span><br><span class="line">  if (bias_term_ &amp;&amp; bias_shape !&#x3D; this-&gt;blobs_[1]-&gt;shape()) &#123;</span><br><span class="line">    Blob&lt;Dtype&gt; bias_shaped_blob(bias_shape);</span><br><span class="line">    LOG(FATAL) &lt;&lt; &quot;Incorrect bias shape: expected shape &quot;</span><br><span class="line">        &lt;&lt; bias_shaped_blob.shape_string() &lt;&lt; &quot;; instead, shape was &quot;</span><br><span class="line">        &lt;&lt; this-&gt;blobs_[1]-&gt;shape_string();</span><br><span class="line">  &#125;</span><br><span class="line">  LOG(INFO) &lt;&lt; &quot;Skipping parameter initialization&quot;;</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  if (bias_term_) &#123;</span><br><span class="line">    this-&gt;blobs_.resize(2);</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    this-&gt;blobs_.resize(1);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>如果没有开 <code>bias</code>的话，那么 <code>blob</code>的size就是1，只存了权值，如果开了的话就是2，所以它和这个 <code>1+bias_term</code>做比较看看是否相等。其实这样写是个非常差劲的写法，很具有迷惑性，但是结果肯定是对的，因为布尔变量为true就是1.<br>然后初始化权值和bias</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  &#x2F;&#x2F; Initialize and fill the weights:</span><br><span class="line">  &#x2F;&#x2F; output channels x input channels per-group x kernel height x kernel width</span><br><span class="line">  this-&gt;blobs_[0].reset(new Blob&lt;Dtype&gt;(weight_shape));</span><br><span class="line">  shared_ptr&lt;Filler&lt;Dtype&gt; &gt; weight_filler(GetFiller&lt;Dtype&gt;(</span><br><span class="line">      this-&gt;layer_param_.convolution_param().weight_filler()));</span><br><span class="line">  weight_filler-&gt;Fill(this-&gt;blobs_[0].get());</span><br><span class="line">  &#x2F;&#x2F; If necessary, initialize and fill the biases.</span><br><span class="line">  if (bias_term_) &#123;</span><br><span class="line">    this-&gt;blobs_[1].reset(new Blob&lt;Dtype&gt;(bias_shape));</span><br><span class="line">    shared_ptr&lt;Filler&lt;Dtype&gt; &gt; bias_filler(GetFiller&lt;Dtype&gt;(</span><br><span class="line">        this-&gt;layer_param_.convolution_param().bias_filler()));</span><br><span class="line">    bias_filler-&gt;Fill(this-&gt;blobs_[1].get());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从文件中读取权值，然后填给blob里面。<br>接着获取一下卷积核的总大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernel_dim_ &#x3D; this-&gt;blobs_[0]-&gt;count(1);</span><br></pre></td></tr></table></figure>
<p>这个 <code>count</code>就是总的大小，比方说卷积核形状是3<em>5</em>5，那么 <code>count</code>的结果就是75，而加了个参数就是从第几位开始，那么 <code>count(1)</code>就是5*5=25<br>因为第0位就是输入的channel，这个和卷积核没什么关系，所以从1开始数，用来分配矩阵的大小。<br>接着根据分组情况找一下权值的指针偏移量，方便换组的时候知道往后数多少位</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weight_offset_ &#x3D; conv_out_channels_ * kernel_dim_ &#x2F; group_;</span><br></pre></td></tr></table></figure>
<p>最后在 <code>blob</code>里给反向传播腾个位置就结束了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Propagate gradients to the parameters (as directed by backward pass).</span><br><span class="line">this-&gt;param_propagate_down_.resize(this-&gt;blobs_.size(), true);</span><br></pre></td></tr></table></figure>

<h2 id="Reshape-函数"><a href="#Reshape-函数" class="headerlink" title="Reshape 函数"></a>Reshape 函数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">virtual void Reshape(const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; bottom,</span><br><span class="line">    const vector&lt;Blob&lt;Dtype&gt;*&gt;&amp; top);</span><br></pre></td></tr></table></figure>
<p><code>Reshape</code>函数传入了两个参数，一个 <code>bottom</code>一个 <code>top</code>。<br>一开始还是获取了 <code>first_spatial_axis</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">const int first_spatial_axis &#x3D; channel_axis_ + 1;</span><br></pre></td></tr></table></figure>
<p>然后开始检查 <code>spatial_axis</code>和 <code>bottom</code>的<code>num_axes</code>是不是一致的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CHECK_EQ(bottom[0]-&gt;num_axes(), first_spatial_axis + num_spatial_axes_)</span><br><span class="line">    &lt;&lt; &quot;bottom num_axes may not change.&quot;;</span><br></pre></td></tr></table></figure>
<p>如果不一致的话他就会抛出异常，然后告诉你这个维度可能被改变过。<br>接下来获取输入的维度数量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">num_ &#x3D; bottom[0]-&gt;count(0, channel_axis_);</span><br><span class="line">CHECK_EQ(bottom[0]-&gt;shape(channel_axis_), channels_)</span><br><span class="line">    &lt;&lt; &quot;Input size incompatible with convolution kernel.&quot;;</span><br></pre></td></tr></table></figure>
<p>然后写了个循环遍历所有的<code>bottom</code>，因为这些<code>bottom</code>可能来自不同的<code>blob</code>，所以我们挨个去遍历他。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; TODO: generalize to handle inputs of different shapes.</span><br><span class="line">for (int bottom_id &#x3D; 1; bottom_id &lt; bottom.size(); ++bottom_id) &#123;</span><br><span class="line">  CHECK(bottom[0]-&gt;shape() &#x3D;&#x3D; bottom[bottom_id]-&gt;shape())</span><br><span class="line">      &lt;&lt; &quot;shape mismatch - bottom[0]: &quot; &lt;&lt; bottom[0]-&gt;shape_string()</span><br><span class="line">      &lt;&lt; &quot; vs. bottom[&quot; &lt;&lt; bottom_id &lt;&lt; &quot;]: &quot;</span><br><span class="line">      &lt;&lt; bottom[bottom_id]-&gt;shape_string();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果发现有某一个<code>bottom blob</code>形状不一样的话，它也会抛出异常，因为这样就没法统一进行下去了。<br>然后这些检查完毕之后，就获取了<code>bottom</code>的形状，然后去计算输出的形状。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Shape the tops.</span><br><span class="line">bottom_shape_ &#x3D; &amp;bottom[0]-&gt;shape();</span><br><span class="line">compute_output_shape();</span><br></pre></td></tr></table></figure>
<p>它计算输出的形状是根据不同层使用了不同的算法的，所以这里也没有实现，只有一个虚函数放在这里，我们可以来看一下。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Compute height_out_ and width_out_ from other parameters.</span><br><span class="line">virtual void compute_output_shape() &#x3D; 0;</span><br></pre></td></tr></table></figure>
<p>接着定义了<code>top_shape</code>这个<code>vector</code>，注意，这里还是<code>shape</code>的<code>vector</code>，不是<code>top</code>这个<code>blob</code>的<code>vector</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vector&lt;int&gt; top_shape(bottom[0]-&gt;shape().begin(),</span><br><span class="line">    bottom[0]-&gt;shape().begin() + channel_axis_);</span><br></pre></td></tr></table></figure>
<p>首先把输出的个数赋值给它</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">top_shape.push_back(num_output_);</span><br></pre></td></tr></table></figure>
<p>然后把各个维度的大小写个循环赋值</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (int i &#x3D; 0; i &lt; num_spatial_axes_; ++i) &#123;</span><br><span class="line">  top_shape.push_back(output_shape_[i]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>紧接着我们把传进来的这个<code>top</code><code>blob</code>挨个的<code>reshape</code>成我们想要的这个<code>shape</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (int top_id &#x3D; 0; top_id &lt; top.size(); ++top_id) &#123;</span><br><span class="line">  top[top_id]-&gt;Reshape(top_shape);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同时这里也是要判断一下是不是要反过来，就是给反卷积用的，如果是的话，就要把输出和输入的位置交换</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">if (reverse_dimensions()) &#123;</span><br><span class="line">  conv_out_spatial_dim_ &#x3D; bottom[0]-&gt;count(first_spatial_axis);</span><br><span class="line">&#125; else &#123;</span><br><span class="line">  conv_out_spatial_dim_ &#x3D; top[0]-&gt;count(first_spatial_axis);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来算出原图的计算矩阵的空间大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">col_offset_ &#x3D; kernel_dim_ * conv_out_spatial_dim_;</span><br></pre></td></tr></table></figure>
<p>因为这个矩阵的行数就是<code>kernel_dim_</code>，而列数呢就是要卷积多少次，也就是<code>conv_out_spatial_dim_</code>，比如说输出是3*3维的，那么就有9列<br>这个<code>col_offset_</code>在<code>caffe_cpu_gemm</code>中用到了，方便做矩阵运算的之后指针切换到下一张图用的偏移量。<br>然后是<code>output_offset_</code>就是算出结果的输出的矩阵，就是<code>output</code>的输出的数量。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output_offset_ &#x3D; conv_out_channels_ * conv_out_spatial_dim_ &#x2F; group_;</span><br></pre></td></tr></table></figure>
<p>它最后还除了一个<code>group</code>就是假设有分组的情况下，它是一组一组的计算的，所以每次的偏移量都是这个组内的数量。<br>接着定义了一个输入维度的<code>vector</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Setup input dimensions (conv_input_shape_).</span><br><span class="line">vector&lt;int&gt; bottom_dim_blob_shape(1, num_spatial_axes_ + 1);</span><br></pre></td></tr></table></figure>
<p>这里容易让人产生误解，其实它是一个维度为1的<code>vector</code>，其实完全可以写成一个变量的，他的值是<code>num_spatial_axes_ + 1</code><br>为什么是+1呢？因为这里这个变量的作用是用来初始化形状数组用的，形状数组除了记录了空间维度以外，还要记录channel的数量，所以多留了一位存channel用的。这里用一个<code>vector</code>表示而不是用一个int变量表示完全是为了接口统一，方便下一步的处理。<br>下一步就开始<code>reshape</code>形状的数组了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conv_input_shape_.Reshape(bottom_dim_blob_shape);</span><br></pre></td></tr></table></figure>
<p>紧接着定义了一个指针指向了它，这样做的目的是为了方便下一步去用这个指针去修改它的值。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int* conv_input_shape_data &#x3D; conv_input_shape_.mutable_cpu_data();</span><br></pre></td></tr></table></figure>
<p>接着把各个维度的真实大小一一赋值给它</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for (int i &#x3D; 0; i &lt; num_spatial_axes_ + 1; ++i) &#123;</span><br><span class="line">  if (reverse_dimensions()) &#123;</span><br><span class="line">    conv_input_shape_data[i] &#x3D; top[0]-&gt;shape(channel_axis_ + i);</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    conv_input_shape_data[i] &#x3D; bottom[0]-&gt;shape(channel_axis_ + i);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接着开始reshape<code>im2col</code>结果的一个<code>buffer</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; The im2col result buffer will only hold one image at a time to avoid</span><br><span class="line">&#x2F;&#x2F; overly large memory usage. In the special case of 1x1 convolution</span><br><span class="line">&#x2F;&#x2F; it goes lazily unused to save memory.</span><br><span class="line">col_buffer_shape_.clear();</span><br></pre></td></tr></table></figure>
<p>这里是<code>im2col</code>的结果，而不是我们最终矩阵计算后的结果，这里其实就是得到一个计算矩阵用的。所以他的形状就是<code>kernel_dim_</code><code>* group_</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">col_buffer_shape_.push_back(kernel_dim_ * group_);</span><br><span class="line">for (int i &#x3D; 0; i &lt; num_spatial_axes_; ++i) &#123;</span><br><span class="line">  if (reverse_dimensions()) &#123;</span><br><span class="line">    col_buffer_shape_.push_back(input_shape(i + 1));</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    col_buffer_shape_.push_back(output_shape_[i]);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">col_buffer_.Reshape(col_buffer_shape_);</span><br></pre></td></tr></table></figure>
<p>接着获取它输入的大小和输出的大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bottom_dim_ &#x3D; bottom[0]-&gt;count(channel_axis_);</span><br><span class="line">top_dim_ &#x3D; top[0]-&gt;count(channel_axis_);</span><br></pre></td></tr></table></figure>
<p>后面一步求了<code>num_kernels_im2col_</code>,它的算法是</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_kernels_im2col_ &#x3D; conv_in_channels_ * conv_out_spatial_dim_;</span><br></pre></td></tr></table></figure>
<p>这里我没有看懂是什么意思，这两个数字相乘让人很迷，而且它实际的用途只有在<code>im2col_nd_gpu</code>这一个函数中才用到了，其他的都没有用到，这个函数是什么意思我也没有搞明白。<br>后面还有一个它反向操作的变量</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">num_kernels_col2im_ &#x3D; reverse_dimensions() ? top_dim_ : bottom_dim_;</span><br></pre></td></tr></table></figure>
<p>接下来设置了一下输出的空间大小</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Set up the all ones &quot;bias multiplier&quot; for adding biases by BLAS</span><br><span class="line">out_spatial_dim_ &#x3D; top[0]-&gt;count(first_spatial_axis);</span><br></pre></td></tr></table></figure>
<p>如果设置了<code>bias</code>的话，我们就要reshape这个<code>bias_multiplier_</code>的大小。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if (bias_term_) &#123;</span><br><span class="line">  vector&lt;int&gt; bias_multiplier_shape(1, out_spatial_dim_);</span><br><span class="line">  bias_multiplier_.Reshape(bias_multiplier_shape);</span><br><span class="line">  caffe_set(bias_multiplier_.count(), Dtype(1),</span><br><span class="line">      bias_multiplier_.mutable_cpu_data());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>它最后使用的是<code>caffe_set</code>这个函数，把所有的<code>bias</code>先全部初始化为1</p>
<h2 id="MinBottomBlobs-函数"><a href="#MinBottomBlobs-函数" class="headerlink" title="MinBottomBlobs 函数"></a>MinBottomBlobs 函数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">virtual inline int MinBottomBlobs() const &#123; return 1; &#125;</span><br></pre></td></tr></table></figure>
<p>这个函数是个虚函数，也就是留给子类来实现的，也就是把<code>BottomBlobs</code>最小值返回回去</p>
<h2 id="forward-cpu-gemm-函数"><a href="#forward-cpu-gemm-函数" class="headerlink" title="forward_cpu_gemm 函数"></a>forward_cpu_gemm 函数</h2><p>使用cpu的前传函数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; Helper functions that abstract away the column buffer and gemm arguments.</span><br><span class="line">&#x2F;&#x2F; The last argument in forward_cpu_gemm is so that we can skip the im2col if</span><br><span class="line">&#x2F;&#x2F; we just called weight_cpu_gemm with the same input.</span><br><span class="line">void forward_cpu_gemm(const Dtype* input, const Dtype* weights,</span><br><span class="line">    Dtype* output, bool skip_im2col &#x3D; false);</span><br></pre></td></tr></table></figure>
<p>第一步先生成<code>im2col</code>的矩阵</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">const Dtype* col_buff &#x3D; input;</span><br><span class="line">if (!is_1x1_) &#123;</span><br><span class="line">  if (!skip_im2col) &#123;</span><br><span class="line">    conv_im2col_cpu(input, col_buffer_.mutable_cpu_data());</span><br><span class="line">  &#125;</span><br><span class="line">  col_buff &#x3D; col_buffer_.cpu_data();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后根据分组来进行卷积计算</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for (int g &#x3D; 0; g &lt; group_; ++g) &#123;</span><br><span class="line">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, conv_out_channels_ &#x2F;</span><br><span class="line">      group_, conv_out_spatial_dim_, kernel_dim_,</span><br><span class="line">      (Dtype)1., weights + weight_offset_ * g, col_buff + col_offset_ * g,</span><br><span class="line">      (Dtype)0., output + output_offset_ * g);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="forward-cpu-bias-函数"><a href="#forward-cpu-bias-函数" class="headerlink" title="forward_cpu_bias 函数"></a>forward_cpu_bias 函数</h2><p>计算偏移量，因为caffe的前传把计算权值和偏移量分开算了，主要就是方便矩阵计算的操作，没有什么难懂的地方。<br>它用的函数是一样的，但是这次权值那个位置都设置的1，只计算<code>bias</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasNoTrans, num_output_,</span><br><span class="line">    out_spatial_dim_, 1, (Dtype)1., bias, bias_multiplier_.cpu_data(),</span><br><span class="line">    (Dtype)1., output);</span><br></pre></td></tr></table></figure>
<h2 id="backward-cpu-bias-函数"><a href="#backward-cpu-bias-函数" class="headerlink" title="backward_cpu_bias 函数"></a>backward_cpu_bias 函数</h2><p>这个函数求出当前层<code>bias</code>的梯度<br>因为<code>y=w*x+b</code>，那么可以得知<code>bias</code>的梯度就是1乘以上一层传下来的梯度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">caffe_cpu_gemv&lt;Dtype&gt;(CblasNoTrans, num_output_, out_spatial_dim_, 1.,</span><br><span class="line">    input, bias_multiplier_.cpu_data(), 1., bias);</span><br></pre></td></tr></table></figure>
<p>因为我们<code>bias_multiplier_</code>设置的就是1，所以这个函数翻译过来就是<code>bias = bias *1 + input * bias_multiplier_<code>,所以 <code>bias = bias + input<code><br>这里这个加号是什么意思呢？因为一个batch里面是所有的图加起来求得平均值，所以要先把这个batch里的数据都先加起来，方便之后求平均。</p>
<h2 id="weight-cpu-gemm"><a href="#weight-cpu-gemm" class="headerlink" title="weight_cpu_gemm"></a>weight_cpu_gemm</h2><p>求权重的梯度<br>根据公式<code>y=w*x+b</code>，那么可以得知<code>weight</code>的梯度就是x乘以上一层传下来的梯度</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">const Dtype* col_buff &#x3D; input;</span><br><span class="line">if (!is_1x1_) &#123;</span><br><span class="line">  conv_im2col_cpu(input, col_buffer_.mutable_cpu_data());</span><br><span class="line">  col_buff &#x3D; col_buffer_.cpu_data();</span><br><span class="line">&#125;</span><br><span class="line">for (int g &#x3D; 0; g &lt; group_; ++g) &#123;</span><br><span class="line">  caffe_cpu_gemm&lt;Dtype&gt;(CblasNoTrans, CblasTrans, conv_out_channels_ &#x2F; group_,</span><br><span class="line">      kernel_dim_, conv_out_spatial_dim_,</span><br><span class="line">      (Dtype)1., output + output_offset_ * g, col_buff + col_offset_ * g,</span><br><span class="line">      (Dtype)1., weights + weight_offset_ * g);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最终算出来的值就给了<code>weights + weight_offset_ * g</code>这个位置的数组</p>
<h2 id="backward-cpu-gemm-函数"><a href="#backward-cpu-gemm-函数" class="headerlink" title="backward_cpu_gemm 函数"></a>backward_cpu_gemm 函数</h2><p>这个函数是由损失函数那里传来的这一层的梯度，这一层的梯度其实就是y对于x的求导<br>因为<code>y=w<em>x+b</code>，所以y对于x的求导其实就是w<br>那么总的梯度就应该是上一层的梯度</em>w</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Dtype* col_buff &#x3D; col_buffer_.mutable_cpu_data();</span><br><span class="line">if (is_1x1_) &#123;</span><br><span class="line">  col_buff &#x3D; input;</span><br><span class="line">&#125;</span><br><span class="line">for (int g &#x3D; 0; g &lt; group_; ++g) &#123;</span><br><span class="line">  caffe_cpu_gemm&lt;Dtype&gt;(CblasTrans, CblasNoTrans, kernel_dim_,</span><br><span class="line">      conv_out_spatial_dim_, conv_out_channels_ &#x2F; group_,</span><br><span class="line">      (Dtype)1., weights + weight_offset_ * g, output + output_offset_ * g,</span><br><span class="line">      (Dtype)0., col_buff + col_offset_ * g);</span><br><span class="line">&#125;</span><br><span class="line">if (!is_1x1_) &#123;</span><br><span class="line">  conv_col2im_cpu(col_buff, input);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

    </article>
    <!-- license  -->
    
        <div class="license-wrapper">
            <p>Author：<a href="http://blog.357573.com">keefe</a>
            <p>原文链接：<a href="http://blog.357573.com/2020/03/05/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E5%85%AD%E3%80%8Bbase-conv-layer/">http://blog.357573.com/2020/03/05/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E5%85%AD%E3%80%8Bbase-conv-layer/</a>
            <p>发表日期：<a href="http://blog.357573.com/2020/03/05/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E5%85%AD%E3%80%8Bbase-conv-layer/">March 5th 2020, 8:46:35 pm</a>
            <p>更新日期：<a href="http://blog.357573.com/2020/03/05/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E5%85%AD%E3%80%8Bbase-conv-layer/">April 7th 2020, 4:41:09 pm</a>
            <p>版权声明：本文采用<a rel="license noopener" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a>进行许可</p>
        </div>
    
    <!-- paginator  -->
    <ul class="post-paginator">
        <li class="next">
            
                <div class="nextSlogan">Next Post</div>
                <a href= "/2020/04/07/C++%E5%A4%9A%E7%BA%BF%E7%A8%8B/" title= "C++多线程">
                    <div class="nextTitle">C++多线程</div>
                </a>
            
        </li>
        <li class="previous">
            
                <div class="prevSlogan">Previous Post</div>
                <a href= "/2020/03/04/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E5%85%AD%E3%80%8Bim2col/" title= "caffe源码阅读《六》im2col">
                    <div class="prevTitle">caffe源码阅读《六》im2col</div>
                </a>
            
        </li>
    </ul>
    <!-- 评论插件 -->
    <!-- 来必力City版安装代码 -->

<!-- City版安装代码已完成 -->
    
    
    <!-- partial('_partial/comment/changyan') -->
    <!--PC版-->


    
    
    <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
    <script src='//unpkg.com/valine/dist/Valine.min.js'></script>
    <div id="comment"></div>
    <script>
    new Valine({
        el: '#comment' ,
        notify:false, 
        verify:false, 
        appId: "fEwKgouhKR7SgknNaVaY9gfj-gzGzoHsz",
        appKey: "GkwepWrdx8DC6DJIn7VxjKUa",
        placeholder: "",
        path:window.location.pathname, 
        avatar:'mm' 
    });
    </script>


    <!-- 评论 -->
</main>
            <!-- profile -->
            
        </div>
        <footer class="footer footer-unloaded">
    <!-- social  -->
    
    <div class="social">
        
    
        
            
                <a href="mailto:2375037953@qq.com" class="iconfont-archer email" title=email ></a>
            
        
    
        
            
                <a href="//github.com/keefeWu" class="iconfont-archer github" target="_blank" title=github></a>
            
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
            
                <a href="/assets/bilibili.png" class="iconfont-archer bilibili" target="_blank" title=bilibili></a>
            
        
    
        
    
        
    
        
    
        
    

    </div>
    
    <!-- powered by Hexo  -->
    <div class="copyright">
        <span id="hexo-power">Powered by <a href="https://hexo.io/" target="_blank">Hexo</a></span><span class="iconfont-archer power">&#xe635;</span><span id="theme-info">theme <a href="https://github.com/fi3ework/hexo-theme-archer" target="_blank">Archer</a></span>
    </div>
    <!-- 不蒜子  -->
    
    <div class="busuanzi-container">
    
     
    <span>PV: <span id="busuanzi_value_site_pv"></span> :)</span>
    
    </div>
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
</footer>


    </div>
    <!-- toc -->
    
    <div class="toc-wrapper" style=
    







top:50vh;

    >
        <div class="toc-catalog">
            <span class="iconfont-archer catalog-icon">&#xe613;</span><span>CATALOG</span>
        </div>
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#BaseConvolutionLayer-类"><span class="toc-number">1.</span> <span class="toc-text">BaseConvolutionLayer 类</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#BaseConvolutionLayer-构造函数"><span class="toc-number">1.1.</span> <span class="toc-text">BaseConvolutionLayer 构造函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#LayerSetUp-函数"><span class="toc-number">1.2.</span> <span class="toc-text">LayerSetUp 函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reshape-函数"><span class="toc-number">1.3.</span> <span class="toc-text">Reshape 函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MinBottomBlobs-函数"><span class="toc-number">1.4.</span> <span class="toc-text">MinBottomBlobs 函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#forward-cpu-gemm-函数"><span class="toc-number">1.5.</span> <span class="toc-text">forward_cpu_gemm 函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#forward-cpu-bias-函数"><span class="toc-number">1.6.</span> <span class="toc-text">forward_cpu_bias 函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#backward-cpu-bias-函数"><span class="toc-number">1.7.</span> <span class="toc-text">backward_cpu_bias 函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#weight-cpu-gemm"><span class="toc-number">1.8.</span> <span class="toc-text">weight_cpu_gemm</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#backward-cpu-gemm-函数"><span class="toc-number">1.9.</span> <span class="toc-text">backward_cpu_gemm 函数</span></a></li></ol></li></ol>
    </div>
    
    <div class="back-top iconfont-archer">&#xe639;</div>
    <div class="sidebar sidebar-hide">
    <ul class="sidebar-tabs sidebar-tabs-active-0">
        <li class="sidebar-tab-archives"><span class="iconfont-archer">&#xe67d;</span><span class="tab-name">Archive</span></li>
        <li class="sidebar-tab-tags"><span class="iconfont-archer">&#xe61b;</span><span class="tab-name">Tag</span></li>
        <li class="sidebar-tab-categories"><span class="iconfont-archer">&#xe666;</span><span class="tab-name">Cate</span></li>
    </ul>
    <div class="sidebar-content sidebar-content-show-archive">
          <div class="sidebar-panel-archives">
    <!-- 在ejs中将archive按照时间排序 -->
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <div class="total-and-search">
        <div class="total-archive">
        Total : 118
        </div>
        <!-- search  -->
        
    </div>
    
    <div class="post-archive">
    
    
    
    
    <div class="archive-year"> 2020 </div>
    <ul class="year-list">
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/20</span><a class="archive-post-title" href= "/2020/08/20/pytorch%E8%AF%A6%E8%A7%A3-%E4%B8%80-%E6%95%B0%E6%8D%AE%E6%B5%81/" >pytorch详解<一>数据流</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/17</span><a class="archive-post-title" href= "/2020/08/17/c-CUDA%E7%BC%96%E7%A8%8B%E4%BA%8C%E7%BB%B4%E7%9F%A9%E9%98%B5%E7%9A%84%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/" >c++-CUDA编程二维矩阵的性能优化</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/17</span><a class="archive-post-title" href= "/2020/08/17/c-CUDA%E7%BC%96%E7%A8%8B%E3%80%8A%E3%80%87%E3%80%8B-%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C/" >c-CUDA编程《〇》-七个基本步骤</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">08/06</span><a class="archive-post-title" href= "/2020/08/06/UE4%E6%80%BB%E7%BB%93/" >UE4总结</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">07/03</span><a class="archive-post-title" href= "/2020/07/03/opencv%E5%AE%9E%E7%8E%B0%E4%BA%8C%E7%BB%B4%E7%A0%81%E6%A3%80%E6%B5%8B/" >opencv实现二维码检测</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/14</span><a class="archive-post-title" href= "/2020/04/14/gitlab%E6%90%AD%E5%BB%BA/" >gitlab搭建</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/09</span><a class="archive-post-title" href= "/2020/04/09/linux%E8%BF%90%E7%BB%B4-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/" >linux运维-常用命令</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/07</span><a class="archive-post-title" href= "/2020/04/07/fsck----Linux%E7%A1%AC%E7%9B%98%E4%BF%AE%E5%A4%8D/" >fsck----Linux硬盘修复</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/07</span><a class="archive-post-title" href= "/2020/04/07/c++%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6/" >c++读取文件</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/07</span><a class="archive-post-title" href= "/2020/04/07/JNI-java%E8%B0%83%E7%94%A8c++%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9C%80%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/" >JNI-java调用c++程序的最常用方法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/07</span><a class="archive-post-title" href= "/2020/04/07/C++static%E7%B1%BB%E6%88%90%E5%91%98%EF%BC%8Cstatic%E7%B1%BB%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0/" >C++static类成员，static类成员函数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">04/07</span><a class="archive-post-title" href= "/2020/04/07/C++%E5%A4%9A%E7%BA%BF%E7%A8%8B/" >C++多线程</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/05</span><a class="archive-post-title" href= "/2020/03/05/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E5%85%AD%E3%80%8Bbase-conv-layer/" >caffe源码阅读《六》base_conv_layer</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">03/04</span><a class="archive-post-title" href= "/2020/03/04/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E5%85%AD%E3%80%8Bim2col/" >caffe源码阅读《六》im2col</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/29</span><a class="archive-post-title" href= "/2020/02/29/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E4%BA%94%E3%80%8Bsolver/" >caffe源码阅读《五》solver</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/28</span><a class="archive-post-title" href= "/2020/02/28/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E5%9B%9B%E3%80%8Bnet/" >caffe源码阅读《四》net</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/26</span><a class="archive-post-title" href= "/2020/02/26/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E4%B8%89%E3%80%8Bblob/" >caffe源码阅读《三》blob</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/25</span><a class="archive-post-title" href= "/2020/02/25/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E4%BA%8C%E3%80%8Blayer/" >caffe源码阅读《二》layer</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/19</span><a class="archive-post-title" href= "/2020/02/19/maskrcnn%E8%AE%AD%E7%BB%83%E9%85%8D%E7%BD%AE/" >maskrcnn训练配置</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E4%B8%80%E3%80%8B%E8%AE%AD%E7%BB%83%E5%85%A5%E5%8F%A3/" >caffe源码阅读《一》训练入口</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E5%9F%BA%E4%BA%8E%E6%9A%97%E9%80%9A%E9%81%93%E7%9A%84%E5%9B%BE%E5%83%8F%E5%8E%BB%E9%9B%BE/" >基于暗通道的图像去雾</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/adaboost%E7%9A%84%E9%80%9A%E4%BF%97%E7%90%86%E8%A7%A3/" >adaboost的通俗理解</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E4%BB%80%E4%B9%88%E6%98%AF%E5%8D%B7%E7%A7%AF%E5%91%A2/" >什么是卷积呢</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E8%85%90%E8%9A%80%E3%80%81%E8%86%A8%E8%83%80%E4%BB%A5%E5%8F%8A%E5%BC%80%E9%97%AD%E6%93%8D%E4%BD%9C%E7%AD%89%E5%BD%A2%E6%80%81%E5%AD%A6%E5%A4%84%E7%90%86/" >腐蚀、膨胀以及开闭操作等形态学处理</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E7%94%BB%E5%B0%84%E7%BA%BF%E6%B3%95%E5%88%A4%E6%96%AD%E7%82%B9%E6%98%AF%E5%90%A6%E5%9C%A8%E5%A4%9A%E8%BE%B9%E5%BD%A2%E5%86%85/" >画射线法判断点是否在多边形内</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E7%94%A8CMake%E5%9C%A8windows%E4%B8%8B%E7%BC%96%E8%AF%91vs%E7%9A%84opencv%E7%A8%8B%E5%BA%8F/" >用CMake在windows下编译vs的opencv程序</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%EF%BC%88confusion-matrix%EF%BC%89/" >混淆矩阵（confusion-matrix）</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E5%85%B3%E4%BA%8ELBP%EF%BC%88Local-Binary-Pattern%EF%BC%89%E7%89%B9%E5%BE%81/" >关于LBP（Local-Binary-Pattern）特征</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E5%85%B3%E4%BA%8ELBP%EF%BC%88Local-Binary-Pattern%EF%BC%89%E7%89%B9%E5%BE%81%E3%80%8A%E4%BA%8C%E3%80%8B-%E5%87%A0%E7%A7%8D%E5%8F%98%E7%A7%8D/" >关于LBP（Local-Binary-Pattern）特征《二》-几种变种</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E5%8F%8C%E7%BA%BF%E6%80%A7%E5%B7%AE%E5%80%BC/" >双线性差值</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/caffe%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E5%B0%8F%E7%BB%93%EF%BC%88%E7%95%AA%E5%A4%96%E7%AF%87%EF%BC%89/" >caffe常用指令小结（番外篇）</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/kmeans-%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95/" >kmeans(最简单的机器学习算法)</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/Gabor%E6%BB%A4%E6%B3%A2%E7%9A%84%E5%B1%82%E5%B1%82%E6%80%BB%E7%BB%93/" >Gabor滤波的层层总结</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/pooling%E6%B1%A0%E5%8C%96%E6%93%8D%E4%BD%9C%E7%9A%84%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/" >pooling池化操作的代码详解</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/inode%E8%A7%A3%E9%87%8A%EF%BC%88%E8%A7%A3%E5%86%B3linux%E6%9C%89%E7%A9%BA%E9%97%B4%E5%8D%B4%E6%8F%90%E7%A4%BA%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4%E4%B8%8D%E8%B6%B3%E7%9A%84%E9%97%AE%E9%A2%98%EF%BC%89/" >inode解释（解决linux有空间却提示磁盘空间不足的问题）</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/python%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/" >python那些事儿</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/JNI-java%E8%B0%83%E7%94%A8c-%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9C%80%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95/" >JNI-java调用c++程序的最常用方法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E7%BB%86%E8%AF%B4new%E4%B8%8Emalloc%E7%9A%8410%E7%82%B9%E5%8C%BA%E5%88%AB/" >细说new与malloc的10点区别</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/linux%E5%91%BD%E4%BB%A4/" >linux命令</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/opencv%E4%B8%ADRect%E7%B1%BB%E7%9A%84%E7%A5%9E%E5%A5%87%E7%94%A8%E6%B3%95/" >opencv中Rect类的神奇用法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E6%95%B2%E7%A8%8B%E5%BA%8F%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%80%97%E6%AF%94%E9%97%AE%E9%A2%98/" >敲程序时遇到的一些逗比问题</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/python%E6%9F%A5%E7%9C%8Bimport%E7%9A%84%E7%9B%AE%E5%BD%95/" >python查看import的目录</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/python%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/" >python常用函数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/opencv%E9%BC%A0%E6%A0%87%E7%BB%8F%E8%BF%87%E8%AF%BB%E5%8F%96%E5%9D%90%E6%A0%87%E4%BB%A5%E5%8F%8A%E5%88%92%E5%8A%A8%E7%94%BB%E6%A1%86/" >opencv鼠标经过读取坐标以及划动画框</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/opencv-matchTemplate%E5%87%BD%E6%95%B0%E7%9A%84%E8%A7%A3%E6%9E%90/" >opencv-matchTemplate函数的解析</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/PCL%E5%85%A5%E9%97%A8%E3%80%8A%E4%B8%80%E3%80%8B-%E7%82%B9%E4%BA%91%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" >PCL入门《一》-点云的数据结构</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E8%A7%A3%E9%87%8A%E4%B8%80%E4%B8%8B%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82/" >解释一下全连接层</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/PCL%E5%85%A5%E9%97%A8%E3%80%8A%E4%BA%8C%E3%80%8B%E7%82%B9%E4%BA%91%E7%9A%84%E6%BB%A4%E6%B3%A2/" >PCL入门《二》点云的滤波</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/PCL%E5%85%A5%E9%97%A8%E3%80%8A%E4%B8%89%E3%80%8B%E5%B9%B3%E9%9D%A2%E7%9A%84%E6%B3%95%E7%BA%BF/" >PCL入门《三》平面的法线</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E7%AE%97%E6%B3%95%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3%E4%B8%8Edemo/" >蒙特卡洛算法简单理解与demo</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/KDTree%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3/" >KDTree简单理解</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/SICP%E9%98%85%E8%AF%BB%E7%90%86%E8%A7%A3%E3%80%8A%E7%AC%AC%E4%B8%80%E7%AB%A0%E7%AC%AC%E4%B8%80%E8%8A%82%E3%80%8B/" >SICP阅读理解《第一章第一节》</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/Ubuntu%E8%93%9D%E5%B1%8F%E8%BF%9B%E4%B8%8D%E4%BA%86%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/" >Ubuntu蓝屏进不了图形界面的解决办法</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/PCL%E5%85%A5%E9%97%A8%E3%80%8A%E5%9B%9B%E3%80%8B%E6%A0%B9%E6%8D%AE%E5%90%91%E9%87%8F%E5%81%9A%E7%82%B9%E4%BA%91%E6%97%8B%E8%BD%AC/" >PCL入门《四》根据向量做点云旋转</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E3%80%8A%E6%8C%89%E6%B5%81%E7%A8%8B%E5%88%97%E4%B8%BE%E3%80%8B/" >git常用命令《按流程列举》</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/Linux%E4%B8%8B%E8%AE%BE%E7%BD%AEsh%E6%96%87%E4%BB%B6%E5%8F%8C%E5%87%BB%E6%89%A7%E8%A1%8C/" >Linux下设置sh文件双击执行</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/PCL%E5%85%A5%E9%97%A8%E3%80%8A%E4%BA%94%E3%80%8B%E4%BD%BF%E7%94%A8VOXEL%E7%A8%80%E7%96%8F%E7%82%B9%E4%BA%91/" >PCL入门《五》使用VOXEL稀疏点云</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/PCL%E5%85%A5%E9%97%A8%E3%80%8A%E5%85%AD%E3%80%8B%E4%BD%BF%E7%94%A8Region-growing%E8%BF%9B%E8%A1%8C%E5%B9%B3%E9%9D%A2%E5%88%86%E5%89%B2/" >PCL入门《六》使用Region-growing进行平面分割</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/Linux-%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%BE%AA%E7%8E%AF%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F/" >Linux-命令行循环执行程序</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/PCL%E5%85%A5%E9%97%A8%E3%80%8A%E4%B8%83%E3%80%8B-%E5%8F%AF%E8%A7%86%E5%8C%96PCLVisualizer/" >PCL入门《七》-可视化PCLVisualizer</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/Opencv-3-3-0-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/" >Opencv-3-3-0-常用函数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E4%B8%80%E4%BA%9B%E6%95%B0%E5%AD%A6%E5%90%8D%E8%AF%8D%E7%9A%84%E8%A7%A3%E9%87%8A/" >一些数学名词的解释</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%BC%95%E8%A8%80%E9%A2%98/" >贝叶斯引言题</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/GDB%E5%85%A5%E9%97%A8/" >GDB入门</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/RANSAC%E9%80%9A%E4%BF%97%E8%AE%B2%E8%A7%A3/" >RANSAC通俗讲解</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E6%97%8B%E8%BD%AC%E7%9F%A9%E9%98%B5/" >旋转矩阵</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E4%B8%8B%E8%BD%BDarxiv%E8%AE%BA%E6%96%87%EF%BC%8C%E4%BD%BF%E7%94%A8arxiv%E4%B8%AD%E5%9B%BD%E5%AE%98%E6%96%B9%E9%95%9C%E5%83%8F%E6%9C%8D%E5%8A%A1%E5%99%A8/" >如何快速下载arxiv论文，使用arxiv中国官方镜像服务器</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/C-%E5%A4%9A%E7%BA%BF%E7%A8%8B/" >C++多线程</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/PCL%E5%85%A5%E9%97%A8%E3%80%8A%E5%85%AB%E3%80%8B-RANSAC%E7%9A%84%E5%AE%9E%E7%8E%B0/" >PCL入门《八》-RANSAC的实现</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/pyqt%E5%85%A5%E9%97%A8%EF%BC%88%E5%B8%A6%E9%BC%A0%E6%A0%87%E5%93%8D%E5%BA%94%E4%BA%8B%E4%BB%B6%E7%9A%84QLabel%EF%BC%89/" >pyqt入门（带鼠标响应事件的QLabel）</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/pyqt%E5%85%A5%E9%97%A8%EF%BC%88opencv%E4%B8%8EQLabel%EF%BC%89/" >pyqt入门（opencv与QLabel）</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/c-%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6/" >c++读取文件</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/PCL%E5%85%A5%E9%97%A8%E3%80%8A%E4%B9%9D%E3%80%8B-%E8%BE%93%E5%85%A5%E4%B8%8E%E8%BE%93%E5%87%BA/" >PCL入门《九》-输入与输出</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/fsck-Linux%E7%A1%AC%E7%9B%98%E4%BF%AE%E5%A4%8D/" >fsck----Linux硬盘修复</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/vector%E7%9A%84%E8%89%AF%E5%A5%BD%E4%B9%A0%E6%83%AFreserve/" >vector的良好习惯reserve</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E4%BD%BF%E7%94%A8iptables%E9%99%90%E5%88%B6%E7%94%B5%E8%84%91%E8%AE%BF%E9%97%AE%E6%9F%90%E4%B8%AAip/" >使用iptables限制电脑访问某个ip</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/C-static%E7%B1%BB%E6%88%90%E5%91%98%EF%BC%8Cstatic%E7%B1%BB%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0/" >C++static类成员，static类成员函数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/Vector%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%B8%85%E7%A9%BA%E6%95%B0%E6%8D%AE%E4%B8%8E%E9%87%8A%E6%94%BE%E5%86%85%E5%AD%98/" >Vector的正确清空数据与释放内存</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/git-pro%E7%AC%94%E8%AE%B0-%E3%80%8AGit-%E5%9F%BA%E7%A1%80%E3%80%8B/" >git-pro笔记-《Git-基础》</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/git-pro%E7%AC%94%E8%AE%B0-%E3%80%8AGit-%E5%88%86%E6%94%AF%E3%80%8B/" >git-pro笔记-《Git-分支》</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/SIFT%E4%BB%8B%E7%BB%8D/" >SIFT介绍</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E8%A7%A3%E5%86%B3keras%E7%9A%84attempting-to-perform-BLAS-operation-using-StreamExecutor-without-BLAS-support%E9%97%AE%E9%A2%98/" >解决keras的attempting-to-perform-BLAS-operation-using-StreamExecutor-without-BLAS-support问题</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E6%9E%81%E7%AE%80%E8%A7%A3%E9%87%8Ainception-V1-V2-V3-V4/" >极简解释inception-V1-V2-V3-V4</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E6%AD%A3%E5%88%99%E5%8C%96%E6%96%B9%E6%B3%95%EF%BC%9AL1%E5%92%8CL2-regularization%E3%80%81%E6%95%B0%E6%8D%AE%E9%9B%86%E6%89%A9%E5%A2%9E%E3%80%81dropout/" >正则化方法：L1和L2-regularization、数据集扩增、dropout</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/NMS%E2%80%94%E2%80%94%E9%9D%9E%E6%9E%81%E5%A4%A7%E5%80%BC%E6%8A%91%E5%88%B6/" >NMS——非极大值抑制</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/Deep-Learning%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E5%8F%8A%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A%E6%B1%87%E6%80%BB/" >Deep-Learning笔记（三）-机器学习经典算法及名词解释汇总</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96%E5%87%BD%E6%95%B0%E7%9B%B4%E8%A7%82%E6%98%BE%E7%A4%BA%E5%9B%BE/" >参数优化函数直观显示图</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E4%BB%8ERCNN%E5%88%B0FAST-RCNN%E3%80%81FASTER-RCNN%E5%86%8D%E5%88%B0MASK-RCNN/" >从RCNN到FAST-RCNN、FASTER-RCNN再到MASK-RCNN</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" >机器学习-损失函数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/linux%E8%BF%90%E7%BB%B4-N%E5%8D%A1%E7%94%B5%E8%84%91%E8%A3%85Ubuntu%E5%8D%A1%E4%BD%8F%E9%97%AE%E9%A2%98/" >linux运维-N卡电脑装Ubuntu卡住问题</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/linux%E8%BF%90%E7%BB%B4-doxygen%E5%AE%89%E8%A3%85/" >linux运维-doxygen安装</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E5%92%8C%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%BB%84%E5%90%88%E6%95%88%E6%9E%9C/" >机器学习-代价函数和激活函数组合效果</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/Ubuntu18-04-Caffe-%E5%AE%89%E8%A3%85%E6%AD%A5%E9%AA%A4%E8%AE%B0%E5%BD%95%EF%BC%88%E8%B6%85%E8%AF%A6%E5%B0%BD%EF%BC%89/" >Ubuntu18-04-Caffe-安装步骤记录（超详尽）</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/caffe%E6%B5%8B%E8%AF%95%E7%A8%8B%E5%BA%8F%E3%80%8A%E4%B8%80%E3%80%8Bsoftmax/" >caffe测试程序《一》softmax</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/c-CUDA%E7%BC%96%E7%A8%8B%E3%80%8A%E4%B8%80%E3%80%8B-%E8%AE%A1%E7%AE%97%E7%9F%A9%E9%98%B5%E5%8A%A0%E5%87%8F%E4%B9%98%E9%99%A4/" >c++-CUDA编程《一》-计算矩阵加减乘除</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/caffe%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E3%80%8A%E4%BA%8C%E3%80%8Bsoftmax%E5%B1%82/" >caffe源码阅读《二》softmax层</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-RCNN/" >目标检测-RCNN</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-SPPNet/" >目标检测-SPPNet</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-Fast-RCNN/" >目标检测-Fast-RCNN</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/08</span><a class="archive-post-title" href= "/2020/02/08/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-Faster-RCNN/" >目标检测-Faster-RCNN</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/05</span><a class="archive-post-title" href= "/2020/02/05/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-numpy%E5%90%91%E7%A9%BA%E7%9A%84%E4%BA%8C%E7%BB%B4%E6%95%B0%E7%BB%84%E4%B8%AD%E6%B7%BB%E5%8A%A0%E5%85%83%E7%B4%A0/" >python机器学习-numpy向空的二维数组中添加元素</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/05</span><a class="archive-post-title" href= "/2020/02/05/linux%E8%BF%90%E7%BB%B4-%E5%88%86%E5%8D%B7%E5%8E%8B%E7%BC%A9/" >linux运维-分卷压缩</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/04</span><a class="archive-post-title" href= "/2020/02/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E8%8C%83%E6%95%B0/" >机器学习-范数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/04</span><a class="archive-post-title" href= "/2020/02/04/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-softmax/" >机器学习-softmax</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/03</span><a class="archive-post-title" href= "/2020/02/03/%E5%87%B8%E4%BC%98%E5%8C%96/" >凸优化</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">02/03</span><a class="archive-post-title" href= "/2020/02/03/python%E8%B0%83%E7%94%A8c-%E5%87%BD%E6%95%B0%E4%BC%A0%E9%80%92opencv%E5%9B%BE%E7%89%87/" >python调用c++函数传递opencv图片</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/21</span><a class="archive-post-title" href= "/2020/01/21/linux%E8%BF%90%E7%BB%B4-%E4%BD%BF%E7%94%A8pigz%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%8E%8B%E7%BC%A9/" >linux运维-使用pigz多线程压缩</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/09</span><a class="archive-post-title" href= "/2020/01/09/%E8%AE%BE%E7%BD%AEsupervisor/" >设置supervisor</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/09</span><a class="archive-post-title" href= "/2020/01/09/%E5%8D%B8%E8%BD%BDnvidia%E9%A9%B1%E5%8A%A8/" >卸载nvidia驱动</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/07</span><a class="archive-post-title" href= "/2020/01/07/linux%E8%BF%90%E7%BB%B4-apt%E6%BA%90%E9%94%99%E8%AF%AF/" >linux运维-apt源错误</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/07</span><a class="archive-post-title" href= "/2020/01/07/%E5%90%91caffe%E7%9A%84docker%E4%B8%AD%E6%B7%BB%E5%8A%A0opencv%E5%B9%B6%E4%BF%9D%E5%AD%98/" >向caffe的docker中添加opencv并保存</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/07</span><a class="archive-post-title" href= "/2020/01/07/python%E5%88%9B%E5%BB%BAgrpc%E9%80%9A%E4%BF%A1demo%E8%A7%A3%E6%9E%90/" >python创建grpc通信demo解析</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/07</span><a class="archive-post-title" href= "/2020/01/07/python%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-numpy%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0/" >python机器学习-numpy常用函数</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/07</span><a class="archive-post-title" href= "/2020/01/07/WebFace-%E9%94%99%E8%AF%AF%E4%BA%BA%E8%84%B8/" >WebFace 错误人脸</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/07</span><a class="archive-post-title" href= "/2020/01/07/linux%E8%BF%90%E7%BB%B4-apt%E9%94%81%E9%97%AE%E9%A2%98/" >linux运维-apt锁问题</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/05</span><a class="archive-post-title" href= "/2020/01/05/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-YOLOv2/" >目标检测-YOLOv2</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/05</span><a class="archive-post-title" href= "/2020/01/05/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B-YOLO/" >目标检测-YOLO</a>
        </li>
    
    
        <li class="archive-post-item">
            <span class="archive-post-date">01/01</span><a class="archive-post-title" href= "/2020/01/01/hexo-%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/" >hexo 博客搭建</a>
        </li>
    
    </div>
  </div>
        <div class="sidebar-panel-tags">
    <div class="sidebar-tags-name">
    
        <span class="sidebar-tag-name" data-tags="目标检测"><span class="iconfont-archer">&#xe606;</span>目标检测</span>
    
        <span class="sidebar-tag-name" data-tags="论文解读"><span class="iconfont-archer">&#xe606;</span>论文解读</span>
    
        <span class="sidebar-tag-name" data-tags="算法"><span class="iconfont-archer">&#xe606;</span>算法</span>
    
        <span class="sidebar-tag-name" data-tags="图像处理"><span class="iconfont-archer">&#xe606;</span>图像处理</span>
    
        <span class="sidebar-tag-name" data-tags="YOLO"><span class="iconfont-archer">&#xe606;</span>YOLO</span>
    
        <span class="sidebar-tag-name" data-tags="数据集"><span class="iconfont-archer">&#xe606;</span>数据集</span>
    
        <span class="sidebar-tag-name" data-tags="webface"><span class="iconfont-archer">&#xe606;</span>webface</span>
    
        <span class="sidebar-tag-name" data-tags="人脸识别"><span class="iconfont-archer">&#xe606;</span>人脸识别</span>
    
        <span class="sidebar-tag-name" data-tags="python"><span class="iconfont-archer">&#xe606;</span>python</span>
    
        <span class="sidebar-tag-name" data-tags="numpy"><span class="iconfont-archer">&#xe606;</span>numpy</span>
    
        <span class="sidebar-tag-name" data-tags="caffe"><span class="iconfont-archer">&#xe606;</span>caffe</span>
    
        <span class="sidebar-tag-name" data-tags="docker"><span class="iconfont-archer">&#xe606;</span>docker</span>
    
        <span class="sidebar-tag-name" data-tags="opencv"><span class="iconfont-archer">&#xe606;</span>opencv</span>
    
        <span class="sidebar-tag-name" data-tags="grpc"><span class="iconfont-archer">&#xe606;</span>grpc</span>
    
        <span class="sidebar-tag-name" data-tags="运维"><span class="iconfont-archer">&#xe606;</span>运维</span>
    
        <span class="sidebar-tag-name" data-tags="apt"><span class="iconfont-archer">&#xe606;</span>apt</span>
    
        <span class="sidebar-tag-name" data-tags="守护进程"><span class="iconfont-archer">&#xe606;</span>守护进程</span>
    
        <span class="sidebar-tag-name" data-tags="supervisor"><span class="iconfont-archer">&#xe606;</span>supervisor</span>
    
        <span class="sidebar-tag-name" data-tags="nvidia"><span class="iconfont-archer">&#xe606;</span>nvidia</span>
    
        <span class="sidebar-tag-name" data-tags="cuda"><span class="iconfont-archer">&#xe606;</span>cuda</span>
    
        <span class="sidebar-tag-name" data-tags="c++"><span class="iconfont-archer">&#xe606;</span>c++</span>
    
        <span class="sidebar-tag-name" data-tags="机器学习"><span class="iconfont-archer">&#xe606;</span>机器学习</span>
    
        <span class="sidebar-tag-name" data-tags="调参"><span class="iconfont-archer">&#xe606;</span>调参</span>
    
    </div>
    <div class="iconfont-archer sidebar-tags-empty">&#xe678;</div>
    <div class="tag-load-fail" style="display: none; color: #ccc; font-size: 0.6rem;">
    缺失模块。<br/>
    1、请确保node版本大于6.2<br/>
    2、在博客根目录（注意不是archer根目录）执行以下命令：<br/>
    <span style="color: #f75357; font-size: 1rem; line-height: 2rem;">npm i hexo-generator-json-content --save</span><br/>
    3、在根目录_config.yml里添加配置：
    <pre style="color: #787878; font-size: 0.6rem;">
    jsonContent:
    meta: false
    pages: false
    posts:
        title: true
        date: true
        path: true
        text: false
        raw: false
        content: false
        slug: false
        updated: false
        comments: false
        link: false
        permalink: true
        excerpt: false
        categories: true
        tags: true</pre>
    </div> 
    <div class="sidebar-tags-list"></div>
</div>
        <div class="sidebar-panel-categories">
    <div class="sidebar-categories-name">
    
        <span class="sidebar-category-name" data-categories="论文解读"><span class="iconfont-archer">&#xe60a;</span>论文解读</span>
    
        <span class="sidebar-category-name" data-categories="数据集"><span class="iconfont-archer">&#xe60a;</span>数据集</span>
    
        <span class="sidebar-category-name" data-categories="numpy"><span class="iconfont-archer">&#xe60a;</span>numpy</span>
    
        <span class="sidebar-category-name" data-categories="caffe"><span class="iconfont-archer">&#xe60a;</span>caffe</span>
    
        <span class="sidebar-category-name" data-categories="grpc"><span class="iconfont-archer">&#xe60a;</span>grpc</span>
    
        <span class="sidebar-category-name" data-categories="运维"><span class="iconfont-archer">&#xe60a;</span>运维</span>
    
        <span class="sidebar-category-name" data-categories="caffe源码解读"><span class="iconfont-archer">&#xe60a;</span>caffe源码解读</span>
    
        <span class="sidebar-category-name" data-categories="python"><span class="iconfont-archer">&#xe60a;</span>python</span>
    
        <span class="sidebar-category-name" data-categories="调参"><span class="iconfont-archer">&#xe60a;</span>调参</span>
    
        <span class="sidebar-category-name" data-categories="机器学习"><span class="iconfont-archer">&#xe60a;</span>机器学习</span>
    
        <span class="sidebar-category-name" data-categories="图像处理"><span class="iconfont-archer">&#xe60a;</span>图像处理</span>
    
    </div>
    <div class="iconfont-archer sidebar-categories-empty">&#xe678;</div>
    <div class="sidebar-categories-list"></div>
</div>
    </div>
</div> 
    <script>
    var siteMeta = {
        root: "/",
        author: "keefe"
    }
</script>
    <!-- CDN failover -->
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <script type="text/javascript">
        if (typeof window.$ === 'undefined')
        {
            console.warn('jquery load from jsdelivr failed, will load local script')
            document.write('<script src="/lib/jquery.min.js">\x3C/script>')
        }
    </script>
    <script src="/scripts/main.js"></script>
    <!-- algolia -->
    
    <!-- busuanzi  -->
    
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    
    <!-- CNZZ  -->
    
    </div>
    <!-- async load share.js -->
    
        <script src="/scripts/share.js" async></script>    
     
    </body>
</html>


