---
title: 408
date: 2020-10-26 08:41:35
tags:
---
# 计算机组成原理
## IEEE 754
32位浮点数,指数为2的指数次方
以下序号真实使用时是反过来的
* 1:符号位 -1^x
* 2-9:指数位 我们从阶码的0000-0000开始对应-127~+127共计255个数，所以就有了：阶码=阶码真值+127。
* 10-32:有效数字 只存储了小数部分,最终形式一定是1.x 但是这里只存了x
最终算真值的时候应该是 -1^(符号位)(也就是0是正数1是负数) * 2^(指数位-127) * 1.(有效数字位)
例如:
c800 0000H
就是
1100 1000 0000 0000 0000 0000 0000 0000
符号位是1,就是负数
阶码也就是指数位是10010000,应该是128+16-127=17
有效数字是0,意味着是1.0
所以最终结果是
-2^17*1.0=2^-17

64位浮点数
* 1:符号位
* 2-12:指数位 (-1023-1023)
* 13-64:有效数字 13-32:最高有效位(MSB) 33-64:最低有效位(LSB)

浮点舍入
* 向上取整
* 向下取整
* 向0舍入
* 向偶数舍入
前三个无论正负都是按照数字绝对大小来得,向偶数舍入是.5的时候向附近的一个偶数舍入,这样避免了四舍五入时候每次.5都向上取整,造成误差累积

如果用32位表示带符号整数的话,第一位作为符号位,不参与数值运算
一般用补码表示,所以
c800 0000H
就是
1100 1000 0000 0000 0000 0000 0000 0000
实际上的有效位是
100 1000 0000 0000 0000 0000 0000 0000
第一个1代表是负数
因为这个有效位是补码,所以实际的源码应该是
0011 1000 0000 0000 0000 0000 0000 0000 = (1+2+4) * 2^27
所以最终结果应该是 - 7 * 2 ^27

## CPU

### 数据通路
数据在功能部件之间传送的路径，称为数据通路。比如运算器与寄存器之间的传送路径，就是CPU内部的数据通路。 数据通路描述了信息从什么地方开始，中间经过那个寄存器或者开关，最后传送到哪个寄存器。这些都要加以控制. 数据通路的功能就是实现CPU内部逻辑运算器与寄存器以及寄存器之家的数据交换。
数据通路由操作元件和存储单元通过总线或者分散方式连接而成，由操作元件和状态元件交替组成，即数据通路的基本结构为“-----状态元件----操作元件-------状态元件”
1. 操作元件 常用的操作元件有多路选择器mux，加法器，ALU，译码器等等，有些操作元件不需要控制信号控制。

2. 状态元件 状态元件具有存储功能，输入状态在时钟控制下被写到电路，并保持电路输出值不变，直到下一个时钟到达，输入端状态由时钟决定何时被写入，输出端状态随时可以读出。

3. 时钟控制 指令的执行过程中，每个操作步骤都有先后顺序，为了使得计算机能正确执行指令，CPU必须按正确的时序产生操作控制信号。

指令寄存器:存放指令的寄存器,长度为指令长度,不确定,有半字长、单子长、双字长、多字长的长度类型
程序计数器:又叫PC,这个名字很迷,应该叫做指令地址寄存器的,长度由内存指令存储器的地址位数决定,也就是内存的长度
ALU:逻辑计算单元,他才是和机器长度一样
TLB 缓存了地址，cache 缓存了数据。
增加缓存命中率就是通过增加程序局部性来完成,显而易见.时间局部性就是定义了最好马上用,空间局部性就是连续的内存块最好一起访问
当 CPU 要访问内存时，使用的是虚拟地址，会经由 MMU 转换为物理地址，如果 MMU
在 TLB 中查找到了对应虚拟地址，就可以直接取出物理地址而不需要查找页表，否则
就需要查找页表（相比于在 TLB 中查找很费时，而且可能产生更多的访存）。此时
我们由虚拟地址得到了物理地址，TLB 的作用也就结束了。

然后需要通过物理地址取出内存中的内容，此时会优先查找 cache，如果该物理地址
已经在 cache 中，就可以直接取出，否则就需要进行实际的访存操作（相比于从
cache 中取出非常费时）。

CPU的时钟频率就是主频,主频越大算的越快

PC的值根据CPU在执行指令的过程中修改(准确说是取值周期末),条件转移指令执行时,是需要判断标志寄存器(程序状态寄存器)的状态来决定的
程序计数器的位数和存储器地址的位数相等,存储器地址的位数取决于存储器的容量,即存储器的容量/字长
## 大端序 小端序
先数大的叫大端序,先数小的叫小端序,通常正着数的就是大端序,比方说12345678,存在电脑里也是12 34 56 78,至于为什么说高位地址存低位数这么拗口的记法呢,其实最好忘记这个口诀,因为内存地址也是按顺序编号的啊,1号地址存了12,2号地址存了34,3号存了56,而我们说越到后面数字的位数越低,但是内存地址越大,这样才造成了这样一个反向的东西,建议忘记这个口诀,自己想一想就好了.
大端序是给人看的,小端序是给机器看的,小端序是反的.

## RAM
SRAM一般只有几个MB而已， 再多了就不划算， 因为贵！ 从电路图可以看出， 基本都是一些晶体管运算， 速度很快， 所以SRAM一般用来做高速缓存存储器， 既可以放在cpu芯片上， 也可以放在片下。 SRAM中的S是static的意思。

DRAM的数据实际上是存在于电容里面的， 电容会有电的泄露， 损失状态， 故需要对电容状态进行保持和刷新处理， 以维持持久状态， 而这是需要时间的， 所以就慢了。 这个刷新加动态刷新， 而DRAM中的D就是dynamic的意思。

DRAM比SRAM要慢， 但造价更低， 容量也比SRAM大得多， 在计算机中主要用来做内存， 物尽其用。

RAM ROM都是随机存储器,随机的意思就是随机访问中间的某个位置,不需要像磁带那样倒带.ROM是用来放固件的,比方说一些控制指令,他是不可擦除的.

## 虚拟地址
现在CPU都是通过虚拟寻址访问内存的,翻译虚拟地址的单元叫做内存管理单元MMU(Memory Management Unit)
如果访问的地址不在内存中,则称为缺页,这时候需要去虚拟内存上找,这就是所谓的DRAM缓存不命中,这时候就会产生缺页异常,调用内核中的缺页异常处理程序.缺页异常处理程序会把内存中的某一个位置换成想要的那个

## 多级页表
一个32位的机器地址可以从0到2^32这么多编号,假设一个页面有4KB,也就是2^12位,那么页面地址就是0,2^12,2*2^12,3*2^12...2^32,那么一共就有2^32/2^12项,假设每一项有4字节,也就是PTE(表索引长度)是4,那么一张表需要2^32/2^12*4字节的空间 
## 指令
每一条指令（指的是机器码）一般对应一条汇编语句（指的是使用汇编语言书写的一条指令），所以我们一般就将指令等同于汇编语言

## 多周期CPU
如果所有指令都用相同的时钟周期,那么这个时钟周期当然得设置兼容最慢的那个指令,浪费了不少,所以给他们拆分,动态规划
CPU的指令集Ins中有多条指令，指令4耗时最长，执行一次它需要800ps。

　　　　单周期CPU的时钟周期最少设为800ps。此时假如我们要执行指令1,2,3,4,5,6，那么总共耗时6x800ps=4800ps。

　　　　多周期CPU，分别可以把指令123456分解为3个op，2个op，4个op，8个op，3个op，5个op。每个op延时为100ps。那么假如我们要执行指令1,2,3,4,5,6，则总共耗时为(3+2+4+8+3+5)x100ps=2500ps。

## 自陷
用户想要访问操作系统内核的时候,产生自陷来插队,也就是一个安排好了的异常.像debug就是用的自陷,自陷后cpu就要去执行内核程序了,自陷完了之后会返回到陷阱指令的下一条执行,自陷是内部中断
### 硬件中断
* 外部中断 外部中断一般是指由计算机外设发出的中断请求，如：键盘中断、打印机中断、定时器中断等。外部中断是可以屏蔽的中断，也就是说，利用中断控制器可以屏蔽这些外部设备 的中断请求。
* 内部中断 内部中断是指因硬件出错（如突然掉电、奇偶校验错等）或运算出错（除数为零、运算溢出、单步中断等）所引起的中断。内部中断是不可屏蔽的中断。
### 软件中断
软件中断其实并不是真正的中断，它们只是可被调用执行的一般程序。例如：ROM BIOS中的各种外部设备管理中断服务程序（键盘管理中断、显示器管理中断、打印机管理 中断等，）以及DOS的系统功能调用（INT 21H）等都是软件中断。(用不上)

## NMI (Non Maskable Interrupt)——不可屏蔽中断(即CPU不能屏蔽)
处理器必须接受和处理来自NMI的中断请求。在80386系统中，处理器在响应NMI的中断向量号固定为2。为了避免不可屏蔽中断的嵌套，当接受到一个NMI中断请求时，处理器自动屏蔽所有的NMI的中断请求，直到执行中断指令IRET后才重新开放NMI中断请求，所以，NMI处理程序应以IRET指令结束。
典型的非屏蔽中断源的例子是电源掉电，一旦出现，必须立即无条件地响应，否则进行其他任何工作都是没有意义的。
典型的可屏蔽中断源的例子是打印机中断，CPU对打印机中断请求的响应可以快一些，也可以慢一些，因为让打印机等待会儿是完全可以的。

## DMA 直接存储器访问
它允许不同速度的硬件装置来沟通，而不需要依赖于 CPU 的大量中断负载。否则，CPU 需要从来源把每一片段的资料复制到暂存器，然后把它们再次写回到新的地方。在这个时间中，CPU 对于其他的工作来说就无法使用。
DMA 传输将数据从一个地址空间复制到另外一个地址空间。当CPU 初始化这个传输动作，传输动作本身是由 DMA 控制器来实行和完成。典型的例子就是移动一个外部内存的区块到芯片内部更快的内存区。像是这样的操作并没有让处理器工作拖延，反而可以被重新排程去处理其他的工作。

### 请求
CPU对DMA控制器初始化，并向I/O接口发出操作命令，I/O接口提出DMA请求。
### 响应
DMA控制器对DMA请求判别优先级及屏蔽，向总线裁决逻辑提出总线请求。当CPU执行完当前总线周期即可释放总线控制权。此时，总线裁决逻辑输出总线应答，表示DMA已经响应，通过DMA控制器通知I/O接口开始DMA传输。
### 传输
DMA控制器获得总线控制权后，CPU即刻挂起或只执行内部操作，由DMA控制器输出读写命令，直接控制RAM与I/O接口进行DMA传输。
在DMA控制器的控制下，在存储器和外部设备之间直接进行数据传送，在传送过程中不需要中央处理器的参与。开始时需提供要传送的数据的起始位置和数据长度。
### 结束
当完成规定的成批数据传送后，DMA控制器即释放总线控制权，并向I/O接口发出结束信号。当I/O接口收到结束信号后，一方面停 止I/O设备的工作，另一方面向CPU提出中断请求，使CPU从不介入的状态解脱，并执行一段检查本次DMA传输操作正确性的代码。最后，带着本次操作结果及状态继续执行原来的程序。
由此可见，DMA传输方式无需CPU直接控制传输，也没有中断处理方式那样保留现场和恢复现场的过程，通过硬件为RAM与I/O设备开辟一条直接传送数据的通路，使CPU的效率大为提高。

### 传送方式
#### 停止CPU访问内存
先发信号给cpu,让它停止.要求CPU放弃对地址总线、数据总线和有关控制总线的使用权。DMA控制器获得总线控制权以后，开始进行数据传送。在一批数据传送完毕后，DMA控制器通知CPU可以使用内存，并把总线控制权交还给CPU。在这种DMA传送过程中，CPU基本处于不工作状态或者说保持状态。
* 优点: 控制简单，它适用于数据传输率很高的设备进行成组传送。毕竟你让人家等你,你自己必须得快点
* 缺点: 在DMA控制器访问内存阶段，内存的效能没有充分发挥，相当一部分内存工作周期是空闲的。这是因为，外围设备传送两个数据之间的间隔一般总是大于内存存储周期，即使高速I/O设备也是如此。例如，软盘读出一个8位二进制数大约需要32us，而半导体内存的存储周期小于0.5us，因此许多空闲的存储周期不能被CPU利用。

#### 周期挪用
一旦I/O设备有DMA请求，则由I/O设备挪用一个或几个内存周期。
* CPU不需要访内，如CPU正在执行乘法指令。由于乘法指令执行时间较长，此时I/O访内与CPU访内没有冲突，即I/O设备挪用一二个内存周期对CPU执行程序没有任何影响。
* CPU也要求访内 I/O设备访内优先，因为I/O访内有时间要求，前一个I/O数据必须在下一个访问请求到来之前存取完毕。
是一种广泛采用的方法。但是I/O设备每一次周期挪用都有申请总线控制权、建立线控制权和归还总线控制权的过程，所以传送一个字对内存来说要占用一个周期，但对DMA控制器来说一般要2—5个内存周期(视逻辑线路的延迟而定)。因此，周期挪用的方法适用于I/O设备读写周期大于内存存储周期的情况。

#### DMA与CPU交替访问内存
如果CPU的工作周期比内存存取周期长很多，此时采用交替访内的方法可以使DMA传送和CPU同时发挥最高的效率。
这种方式不需要总线使用权的申请、建立和归还过程，总线使用权是通过C1和C2分时制的。CPU和DMA控制器各自有自己的访内地址寄存器、数据寄存器和读/写信号等控制寄存器。在C1周期中，如果DMA控制器有访内请求，可将地址、数据等信号送到总线上。在C2周期中，如CPU有访内请求，同样传送地址、数据等信号。事实上，对于总线，这是用C1，C2控制的一个多路转换器，这种总线控制权的转移几乎不需要什么时间，所以对DMA传送来讲效率是很高的。
这种传送方式又称为“透明的DMA”方式，其来由是这种DMA传送对CPU来说，如同透明的玻璃一般，没有任何感觉或影响。在透明的DMA方式下工作，CPU既不停止主程序的运行，也不进入等待状态，是一种高效率的工作方式。当然，相应的硬件逻辑也就更加复杂。

这里面的周期都是指的内存周期,个人感觉周期挪用和交替访问的区别在于周期挪用是cpu还没干完,就临时让出来了,而交替访问是我完了你上,你完了我再上那种.

## cache
 cache分成多个组，每个组分成多个行，linesize是cache的基本单位，从主存向cache迁移数据都是按照linesize为单位替换的。比如linesize为32Byte，那么迁移必须一次迁移32Byte到cache。 这个linesize比较容易理解，想想我们前面书的例子，我们从书架往书桌搬书必须以书为单位，肯定不能把书撕了以页为单位。书就是linesize。当然了现实生活中每本书页数不同，但是同个cache的linesize总是相同的。
所谓8路组相连（ 8-way set associative）的含义是指，每个组里面有8个行。
对于32位的内存地址，每个line有2^6 = 64Byte，所以地址的【0，5】区分line中的那个字节。一共有64个组。我们取内存地址中间6为来hash查找地址属于那个组。即内存地址的【6，11】位来确定属于64组的哪一个组。组确定了之后，【12，31】的内存地址与组中8个line挨个比对，如果【12，31】为与某个line一致，并且这个line为有效，那么缓存命中。
1 直接映射高速缓存，这个简单，即每个组只有一个line，选中组之后不需要和组中的每个line比对，因为只有一个line。
2 组相联高速缓存，这个就是我们前面介绍的cache。 S个组，每个组E个line。
3 全相联高速缓存，这个简单，只有一个组，就是全相联。不用hash来确定组，直接挨个比对高位地址，来确定是否命中。可以想见这种方式不适合大的缓存。想想看，如果4M 的大缓存　linesize为32Byte，采用全相联的话，就意味着4*1024*1024/32 = 128K 个line挨个比较，来确定是否命中，这是多要命的事情。高速缓存立马成了低速缓存了。
## cache替换策
记住这几个英文
Cache的容量是有限的，当Cache的空间都被占满后，如果再次发生缓存失效，就必须选择一个缓存块来替换掉。常用的替换策略有以下几种：
* 随机算法（Rand）：随机法是随机地确定替换的存储块。设置一个随机数产生器，依据所产生的随机数，确定替换块。这种方法简单、易于实现，但命中率比较低。
* 先进先出算法（FIFO, First In First Out）：先进先出法是选择那个最先调入的那个块进行替换。当最先调入并被多次命中的块，很可能被优先替换，因而不符合局部性规律。这种方法的命中率比随机法好些，但还不满足要求。
* 最久未使用算法（LRU, Least Recently Used）：LRU法是依据各块使用的情况， 总是选择那个最长时间未被使用的块替换。这种方法比较好地反映了程序局部性规律。
* 最不经常使用算法（LFU, Least Frequently Used）：将最近一段时期内，访问次数最少的块替换出Cache。

## 寻址方式
* 按字寻址
* 按字节寻址
一个1MB容量的存储器，字长32位
如果按字寻址,那么就有1M种指令也就是2^20次方种,所以地址范围也就是0-2^20-1
如果按字来寻址,因为一个字是32位,就是4字节,所以一共就是2^18种指令,范围也就成了0-2^18-1

## 总线
总线的最大数据传输率（一秒钟内传输的数据量）
总线带宽计算公式： 总线带宽=总线宽度×时钟频率/周期数

连接CPU和PCI的叫做北桥,连接PCI和ISA的叫做南桥,ISA是主板连接设备的

数据总线

（1） 是CPU与内存或其他器件之间的数据传送的通道。

（2）数据总线的宽度决定了CPU和外界的数据传送速度。

（3）每条传输线一次只能传输1位二进制数据。eg: 8根数据线一次可传送一个8位二进制数据(即一个字节)。

（4）数据总线是数据线数量之和。

地址总线

（1）CPU是通过地址总线来指定存储单元的。

（2）地址总线决定了cpu所能访问的最大内存空间的大小。eg: 10根地址线能访问的最大的内存为1024位二进制数据(1B)

（3）地址总线是地址线数量之和。

控制总线

（1）CPU通过控制总线对外部器件进行控制。

（2）控制总线的宽度决定了CPU对外部器件的控制能力。

（3）控制总线是控制线数量之和。

## 总线仲裁
### 集中仲裁
#### 链式查询
从控制器链式发送信号,谁需要就截取,这样导致离总线控制器近的设备优先级高,排在后面的可能永远抢不到
#### 计数器定是查询
有一个总线请求其BR,需要时候发个信号通过BR传给总线控制器,得到一个取号码,然后挨个来使用总线.这样的好处是可以暗箱操作,想要给某个设备优先级低,就在传给他的那回合把起始编号设高.
#### 独立请求方式
每个设备都有个请求线,可以独立发送请求,然后有总线控制器决定谁的优先级.优点是可以非常灵活决定谁先谁后,缺点是过于复杂.

## IO
因为设备的工作速度慢,所以CPU的指令就从寄存器通过总线发给IO端口,IO端口这里做缓存,然后独立的给IO设备,所以真正的IO指令的数据传输是在CPU寄存器和IO端口之间的

#### 
# 操作系统
## 文件
### 打开文件表
* 系统打开文件表 系统有一张打开文件表,某个文件打开了几次就在里面把打开次数+1,关掉了就-1.
* 用户打开文件表 
## 主存管理
### 分页存储
页面大小=1<<页面偏移量

磁盘读写以扇区作为单位，而系统分配则以簇为单位


## 进程
### 临界资源
仅允许一个进程使用的资源,例如打印机这种,虽然可以共享,但一次智能给一个进程使用
### 临界区
访问临界资源的那段程序成为临界区(临街段)
### 死等状态
进程在有限时间内根本不能进入临界区，而一直在尝试进入，陷入一种无结果的等待状态。
### 忙等状态
当一个进程正处在某临界区内，任何试图进入其临界区的进程都必须进入代码连续循环，陷入忙等状态。连续测试一个变量直到某个值出现为止，称为忙等。
（没有进入临界区的正在等待的某进程不断的在测试循环代码段中的变量的值，占着处理机而不释放，这是一种忙等状态～）-> 这个时候应该释放处理机让给其他进程
### 有限等待
对要求访问临界资源的进程，应保证有限时间内能进入自己的临界区，以免陷入“死等”状态～（受惠的是进程自己）
### 让权等待
当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙等”状态～（受惠的是其他进程）

# 计算机网络
## 协议
网络协议主要由语义,语法,语序三部分构组成,即协议三要素,分别解决讲什么,如何讲,有次序三大问题.
### 应用层
HTTP,FTP,MIME,DHCP这些是应用层的
### 运输层
TCP和UDP是运输层的
### 网络层
ip,路由器,DNS这些是网络层的
### 数据链路层
#### CSMA/CA
一条信道同时只能有一台机器发送数据,如果两台同时发送,就让他们都返回.
电磁波延时为5us/km
计算也非常简单,就是个相遇问题
#### 曼彻斯特编码
为了防止一长串的000或者111分不出来有几个,决定把每个码元拆成两块,如果是0就变成01,1就变成10
### 物理层
信噪比计算
信噪比(S/N)就是信号的平均功率和噪声平均功率之比, 信噪比分贝的计算公式 信噪比(db) = 10lg(S/N)(db)
信道的极限信息传输速率C C=Wlog2(1+S/N)(b/s) W是信道的带宽
奈奎斯特定理 C =2×W×log2M（bps）
带宽是W M个状态 那么信道容量就是 C波特率
## 广播域和冲突域
一个交换机下有N个冲突域,一个路由器下有N个广播域

## ip地址
802.11地址
地址123分别是目的地址,ap地址,源地址
0.0.0.0只能作为源地址不能作为目的地址

## 信道利用率
### 停等协议


# 数据结构
## 折半查找树
根节点为中位数,小的放左边,大的放右边,如果是偶数个,向上取整或者向下取整.但是记住,你如果向下取整,说明根节点小,右边多,那么以下的所有子树都必须满足右边加起来比左边多,哪怕是最后一层.再一个,这个是对半分的子树,肯定是个平衡树,那么这一层没满的时候是绝对不会开新的分支.

## 线索二叉树
左右儿子的指针如果是空就指向前驱和后继,当然前提是有个状态码,是1就表示没有孩子,这个指针指的是前驱或者后继.这个前驱后继是按照某种遍历顺序定的.

## 平衡二叉树
平衡二叉树插入之后需要靠转来调整,就是LL RR LR RL4种情况,注意数清楚究竟是哪个节点是最小不平衡节点,很容易数错的
LL型就是右转,根变成右子树,左子树变成根
RR型就是向左转,根变左子树,右子树变成根
LR型就是先L再R
RL型就是先R再L

## 满二叉树
顾名思义,就是所有节点都是满满的,左右子树齐全

## 完全二叉树
虽然没有满,但是绝对是按照顺序排列的,编号和满一定是一样的

## 树的一些性质
节点的度就是节点孩子的个数,树的度就是最大的那个节点的度,树的总节点数为所有度的和-1,叶子节点的个数也就是总节点数-所有度不为0的节点了

## 哈弗曼树
每次选权值最小的两颗树合并,根节点记录的是权值,根节点就是左右子树权值的和,这样最终从上到下就是权值从大到小了,哈弗曼树一定是左右开花的,没有度为1的节点

## 拓扑排序
把有向无环图弄出一条线性的序列,排序方法为每次都找入度为0的节点,然后再剩余集合中删除这个节点的影响,再接着找入度为0的节点

## 希尔排序
跳着来得插入排序,就是按照一定步长给元素分组,然后组内对换,步长逐渐减小,原先一组的可能分开,但是最终整体步长为1的时候,就是全部元素一个组,那就可以排好了
时间复杂度:O(n方)

## 归并排序
先分割成小块排序,然后两块合并一块
因为每一块都是排好序的,所以弄个i和j分别从左到右,比较左右两边,谁小了就选谁,然后选的那个继续往后移.

## 基数排序
必须是整数,整数时间复杂度都是O(n),就可以先排个位,然后排十位,然后百位这样位置也是稳定的.