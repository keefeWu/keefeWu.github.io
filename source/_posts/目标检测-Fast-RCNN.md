---
title: 目标检测-Fast RCNN
date: 2020-01-05 21:39:02
tags: [目标检测,论文解读,RCNN,算法,图像处理]
categories: 
- 论文解读
---
![在这里插入图片描述](1.png)
　　哈喽大家好，我是蒙特卡洛家的树，时间来到2015年，经历了一年的发展，官方版的快速RCNN问世了。这次出的这个fast rcnn主要借鉴了SPP的方法，共享了featuremap，大大提升了RCNN的效率，另外他自己也有一些创新。就是舍弃了之前的SVM和bbox回归两步，直接在神经网络中完成分类和回归。
![在这里插入图片描述](2.png)
　　他的过程分这么几步。首先是CNN，整张图片输入到神经网络中,算出一个大的featuremap。 然后每个proposal按照比例在featuremap上裁剪丢入空间金字塔池化层。 这时候算出来的不再作为线性的特征了，而是把他当做一个正常的池化，输出的是二维的featuremap，接下来经过一个全连接层。 这个全连接层连接了一对兄弟层，一个输出分类，一个输出bbox。
![在这里插入图片描述](3.png)
　　像SPPNET一样，他是先把整张图经过了一次卷积，然后每个proposal丢到SPP层中，输出2000个固定大小的featuremap。
![在这里插入图片描述](4.png)
　　这里举了例子，因为用了空间金字塔池化，训练的时候一张图有64个ROI，那么由于只需要进行一次前传，所以比RCNN快了64倍。假设batch size是128，那么就选两张图，一张抽64个roi就可以了。
![在这里插入图片描述](5.png)
　　这个网络最大的改进在于他在SPP之后又加入了softmax，直接在网络种算出分类和坐标。把之前的CNN，SVM，坐标回归整合到了一步，这样节省了时间，也避免了硬盘交互。
![在这里插入图片描述](6.png)
　　Fast RCNN的输出用了两个兄弟层，一个是K+1维的softmax概率，K就是想要的类别，+1是加上了背景这一类别。另一个层就是bbox的回归偏移量，这个具体的内容和以前分开的那个回归一样，不过这个是放在了神经网络中做的。
![在这里插入图片描述](7.png)
　　这两个层一起组成了LOSS函数，就是概率的loss加上lambda倍的回归loss。概率的loss用的就是对数损失函数，-LOGpu
![在这里插入图片描述](8.png)
　　而bbox的回归损失函数则是这样的，如果真实的和预测值差<1那么就是0.5倍的差的平方，如果>1就说明预测偏差比较大了，那么损失函数就大一点，就是这个差-0.5
![在这里插入图片描述](9.png)
　　训练时候一个batch是128个ROI，从两张图里得来，一张图取64个ROI。其中有25%的roi是iou大于0.5的，这些作为前景，iou在0.1-0.5之间的作为背景。剩下的作为保留。
![在这里插入图片描述](10.png)
　　Fast RCNN另一个最大的创新就是他发明了一种方法，大大减少了两个连续的全连接层之间的参数个数。假设两个全连接层输出分别维u和v，那么中间的参数就会是u\*v个。但是如果中间加上一个过渡层，他的输出是t，那么这三层的参数就应该是u\*t+v\*t了，而如果我们让t很小，则参数总数就会比u\*v大大的减小了。而怎么样让t很小却又步丢失重要信息呢？其实这个方法就叫做降维，在PCA里面属于基本操作了，而PCA的核心就是使用了SVD的方法。对u\*v那么大的权重矩阵进行奇异值分解，选出奇异值最大的前t个奇异向量作为中间层的权值就可以了。这一步堪称画龙点睛之笔，在过去流行多个全连接层网络的时代有着重要意义。
![在这里插入图片描述](11.png)
　　我们再来看看结果。可以看到，由于删繁就简，FAST RCNN的训练速度只需要一两个小时了，相比之下RCNN和SPP都需要一天多。而测试速度也是高达0.几毫秒了，而SPP颠覆及的加速也才2s。最后看准确率的话其实没什么变动，所以这个网络之所以叫fast rcnn就是因为速度大大的提高了。

